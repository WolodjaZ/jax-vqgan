
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.10">
    
    
      
        <title>How-To Guides üìö - VQGAN JAX/Flax Docs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.472b142f.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.08040f6c.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="None" data-md-color-accent="None">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#how-to-guide" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="VQGAN JAX/Flax Docs" class="md-header__button md-logo" aria-label="VQGAN JAX/Flax Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            VQGAN JAX/Flax Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              How-To Guides üìö
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/WolodjaZ/jax-vqgan" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="VQGAN JAX/Flax Docs" class="md-nav__button md-logo" aria-label="VQGAN JAX/Flax Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    VQGAN JAX/Flax Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/WolodjaZ/jax-vqgan" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Welcome to Docs üëã
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/" class="md-nav__link">
        Tutorials üôá
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          How-To Guides üìö
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        How-To Guides üìö
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#yaml-structures" class="md-nav__link">
    YAML Structures
  </a>
  
    <nav class="md-nav" aria-label="YAML Structures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#loadconfig" class="md-nav__link">
    LoadConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.LoadConfig" class="md-nav__link">
    modules.config.LoadConfig
  </a>
  
    <nav class="md-nav" aria-label="modules.config.LoadConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataconfig" class="md-nav__link">
    DataConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.DataConfig" class="md-nav__link">
    modules.config.DataConfig
  </a>
  
    <nav class="md-nav" aria-label="modules.config.DataConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataparams" class="md-nav__link">
    DataParams
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.DataParams" class="md-nav__link">
    modules.config.DataParams
  </a>
  
    <nav class="md-nav" aria-label="modules.config.DataParams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trainconfig" class="md-nav__link">
    TrainConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.TrainConfig" class="md-nav__link">
    modules.config.TrainConfig
  </a>
  
    <nav class="md-nav" aria-label="modules.config.TrainConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#discconfig" class="md-nav__link">
    DiscConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.DiscConfig" class="md-nav__link">
    modules.config.DiscConfig
  </a>
  
    <nav class="md-nav" aria-label="modules.config.DiscConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vqganconfig" class="md-nav__link">
    VQGANConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.VQGANConfig" class="md-nav__link">
    modules.config.VQGANConfig
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#samples" class="md-nav__link">
    Samples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#major-modules" class="md-nav__link">
    Major Modules
  </a>
  
    <nav class="md-nav" aria-label="Major Modules">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trainervqgan" class="md-nav__link">
    TrainerVQGan
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan" class="md-nav__link">
    modules.training.TrainerVQGan
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.checkpoint_exists" class="md-nav__link">
    checkpoint_exists()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.create_functions" class="md-nav__link">
    create_functions()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.create_train_stat_full" class="md-nav__link">
    create_train_stat_full()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.init_optimizer" class="md-nav__link">
    init_optimizer()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.load_model" class="md-nav__link">
    load_model()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.save_model" class="md-nav__link">
    save_model()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.temperature_scheduling" class="md-nav__link">
    temperature_scheduling()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.train_epoch" class="md-nav__link">
    train_epoch()
  </a>
  
    <nav class="md-nav" aria-label="train_epoch()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vqganpretrainedmodel" class="md-nav__link">
    VQGANPreTrainedModel
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel" class="md-nav__link">
    modules.vqgan.VQGANPreTrainedModel
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.__call__" class="md-nav__link">
    __call__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.decode" class="md-nav__link">
    decode()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.decode_code" class="md-nav__link">
    decode_code()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.encode" class="md-nav__link">
    encode()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.init_weights" class="md-nav__link">
    init_weights()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.update_temperature" class="md-nav__link">
    update_temperature()
  </a>
  
    <nav class="md-nav" aria-label="update_temperature()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vqgandiscriminator" class="md-nav__link">
    VQGanDiscriminator
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGanDiscriminator" class="md-nav__link">
    modules.vqgan.VQGanDiscriminator
  </a>
  
    <nav class="md-nav" aria-label="modules.vqgan.VQGanDiscriminator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflowdataset" class="md-nav__link">
    TensorflowDataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.TensorflowDataset" class="md-nav__link">
    modules.utils.TensorflowDataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.TensorflowDataset.load_dataset" class="md-nav__link">
    load_dataset()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset" class="md-nav__link">
    modules.utils.BaseDataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset.__len__" class="md-nav__link">
    __len__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset.get_dataset" class="md-nav__link">
    get_dataset()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset.load_dataset" class="md-nav__link">
    load_dataset()
  </a>
  
    <nav class="md-nav" aria-label="load_dataset()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataloader" class="md-nav__link">
    DataLoader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.DataLoader" class="md-nav__link">
    modules.utils.DataLoader
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.DataLoader.__call__" class="md-nav__link">
    __call__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.DataLoader.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.DataLoader.__len__" class="md-nav__link">
    __len__()
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../reference/" class="md-nav__link">
        API Reference
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../explanation/" class="md-nav__link">
        Explanation ü§Ø
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../changelog/" class="md-nav__link">
        Changelog ‚è≥
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#yaml-structures" class="md-nav__link">
    YAML Structures
  </a>
  
    <nav class="md-nav" aria-label="YAML Structures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#loadconfig" class="md-nav__link">
    LoadConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.LoadConfig" class="md-nav__link">
    modules.config.LoadConfig
  </a>
  
    <nav class="md-nav" aria-label="modules.config.LoadConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataconfig" class="md-nav__link">
    DataConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.DataConfig" class="md-nav__link">
    modules.config.DataConfig
  </a>
  
    <nav class="md-nav" aria-label="modules.config.DataConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataparams" class="md-nav__link">
    DataParams
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.DataParams" class="md-nav__link">
    modules.config.DataParams
  </a>
  
    <nav class="md-nav" aria-label="modules.config.DataParams">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trainconfig" class="md-nav__link">
    TrainConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.TrainConfig" class="md-nav__link">
    modules.config.TrainConfig
  </a>
  
    <nav class="md-nav" aria-label="modules.config.TrainConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#discconfig" class="md-nav__link">
    DiscConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.DiscConfig" class="md-nav__link">
    modules.config.DiscConfig
  </a>
  
    <nav class="md-nav" aria-label="modules.config.DiscConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vqganconfig" class="md-nav__link">
    VQGANConfig
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.config.VQGANConfig" class="md-nav__link">
    modules.config.VQGANConfig
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#samples" class="md-nav__link">
    Samples
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#major-modules" class="md-nav__link">
    Major Modules
  </a>
  
    <nav class="md-nav" aria-label="Major Modules">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trainervqgan" class="md-nav__link">
    TrainerVQGan
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan" class="md-nav__link">
    modules.training.TrainerVQGan
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.checkpoint_exists" class="md-nav__link">
    checkpoint_exists()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.create_functions" class="md-nav__link">
    create_functions()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.create_train_stat_full" class="md-nav__link">
    create_train_stat_full()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.init_optimizer" class="md-nav__link">
    init_optimizer()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.load_model" class="md-nav__link">
    load_model()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.save_model" class="md-nav__link">
    save_model()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.temperature_scheduling" class="md-nav__link">
    temperature_scheduling()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.training.TrainerVQGan.train_epoch" class="md-nav__link">
    train_epoch()
  </a>
  
    <nav class="md-nav" aria-label="train_epoch()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vqganpretrainedmodel" class="md-nav__link">
    VQGANPreTrainedModel
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel" class="md-nav__link">
    modules.vqgan.VQGANPreTrainedModel
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.__call__" class="md-nav__link">
    __call__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.decode" class="md-nav__link">
    decode()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.decode_code" class="md-nav__link">
    decode_code()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.encode" class="md-nav__link">
    encode()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.init_weights" class="md-nav__link">
    init_weights()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGANPreTrainedModel.update_temperature" class="md-nav__link">
    update_temperature()
  </a>
  
    <nav class="md-nav" aria-label="update_temperature()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#vqgandiscriminator" class="md-nav__link">
    VQGanDiscriminator
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.vqgan.VQGanDiscriminator" class="md-nav__link">
    modules.vqgan.VQGanDiscriminator
  </a>
  
    <nav class="md-nav" aria-label="modules.vqgan.VQGanDiscriminator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorflowdataset" class="md-nav__link">
    TensorflowDataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.TensorflowDataset" class="md-nav__link">
    modules.utils.TensorflowDataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.TensorflowDataset.load_dataset" class="md-nav__link">
    load_dataset()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset" class="md-nav__link">
    modules.utils.BaseDataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset.__len__" class="md-nav__link">
    __len__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset.get_dataset" class="md-nav__link">
    get_dataset()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.BaseDataset.load_dataset" class="md-nav__link">
    load_dataset()
  </a>
  
    <nav class="md-nav" aria-label="load_dataset()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataloader" class="md-nav__link">
    DataLoader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.DataLoader" class="md-nav__link">
    modules.utils.DataLoader
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.DataLoader.__call__" class="md-nav__link">
    __call__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.DataLoader.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#modules.utils.DataLoader.__len__" class="md-nav__link">
    __len__()
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/WolodjaZ/jax-vqgan/edit/master/docs/how-to-guides.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="how-to-guide">How-to guide</h1>
<p>In the project we put every functionality changes into <a href="https://en.wikipedia.org/wiki/YAML">yaml</a> files. Every aspect of tunning, dataset change, trainer change can be done with simply changing parameters in the yaml file. Our pipeline uses <a href="https://hydra.cc">hydra</a> to load and manage pipeline with YAML structures. Firstly we will show you structure of the yaml file and than present you three sample yaml files used in this project. At the end we will also provide major modules used in the pipeline.</p>
<p>If you play to run <code>train.py</code> script your yaml file need to be in <code>conf</code> folder with the name <code>config.yaml</code> as hydra loads this file for the script. If you want to make changes just to them to the fail and for saving for now just rename it ü•∏.</p>
<pre><code>your_project/
‚îÇ
‚îú‚îÄ‚îÄ conf/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ legacy.yaml
‚îÇ
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ losses.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ training.py
‚îÇ   ‚îú‚îÄ‚îÄ utils.py
‚îÇ   ‚îî‚îÄ‚îÄ vqgan.py
‚îÇ
‚îî‚îÄ‚îÄ train.py
</code></pre>
<h2 id="yaml-structures">YAML Structures</h2>
<p>Main yaml config file should have base structure <code>LoadConfig</code> defined in <a href="https://github.com/WolodjaZ/jax-vqgan/blob/e67c52cbb02fc39fbbfacc1ad06f40e6a7d53a79/modules/config.py#L238"><code>modules.config.py</code></a></p>
<h3 id="loadconfig">LoadConfig</h3>


<div class="doc doc-object doc-class">


<a id="modules.config.LoadConfig"></a>
  <div class="doc doc-contents first">

  
      <p>Load configuration class to store the configuration of a train model and data.
Main configuration class to be used for training.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>train</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.config.DataConfig" href="../reference/#modules.config.DataConfig">DataConfig</a></code>
          </td>
          <td><p>data configuration.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>data</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.config.TrainConfig" href="../reference/#modules.config.TrainConfig">TrainConfig</a></code>
          </td>
          <td><p>training configuration.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>modules/config.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">LoadConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Load configuration class to store the configuration of a train model and data.</span>
<span class="sd">    Main configuration class to be used for training.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        train (DataConfig): data configuration.</span>
<span class="sd">        data (TrainConfig): training configuration.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">train</span><span class="p">:</span> <span class="n">TrainConfig</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">DataConfig</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">TrainConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">TrainConfig</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">DataConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DataConfig</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
        <span class="p">)</span>

        <span class="c1"># set resolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">disc_hparams</span><span class="o">.</span><span class="n">resolution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">model_hparams</span><span class="o">.</span><span class="n">resolution</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div><p>Config structure have two parameters <code>data</code> specifying dataset and dataloader parameters and <code>train</code> specifing architecture and training parameters.</p>
<h3 id="dataconfig">DataConfig</h3>


<div class="doc doc-object doc-class">


<a id="modules.config.DataConfig"></a>
  <div class="doc doc-contents first">

  
      <p>Data configuration class.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>train_params</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.config.DataParams" href="../reference/#modules.config.DataParams">DataParams</a></code>
          </td>
          <td><p>training data parameters. Check DataParams for more details.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>test_params</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.config.DataParams" href="../reference/#modules.config.DataParams">DataParams</a></code>
          </td>
          <td><p>testing data parameters. Check DataParams for more details.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dataset_name</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>name of the dataset to use. Currently only supports "voc".</p></td>
          <td>
                <code>&#39;&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>dataset_root</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>root directory of the dataset.</p></td>
          <td>
                <code>&#39;&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>transform</code></td>
          <td>
                <code>optional, dict</code>
          </td>
          <td><p>transform to apply to the dataset. Default None for no transf.
Transform dict comes from albumentations library. Check albumentations for more details.
Loading transform should proceed with albumentations.from_dict method.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>size</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>size of image width and height.</p></td>
          <td>
                <code>224</code>
          </td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>modules/config.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">DataConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Data configuration class.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        train_params (DataParams): training data parameters. Check DataParams for more details.</span>
<span class="sd">        test_params (DataParams): testing data parameters. Check DataParams for more details.</span>
<span class="sd">        dataset_name (str): name of the dataset to use. Currently only supports &quot;voc&quot;.</span>
<span class="sd">        dataset_root (str): root directory of the dataset.</span>
<span class="sd">        transform (optional, dict): transform to apply to the dataset. Default None for no transf.</span>
<span class="sd">            Transform dict comes from albumentations library. Check albumentations for more details.</span>
<span class="sd">            Loading transform should proceed with albumentations.from_dict method.</span>
<span class="sd">        size (int): size of image width and height.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">train_params</span><span class="p">:</span> <span class="n">DataParams</span>
    <span class="n">test_params</span><span class="p">:</span> <span class="n">DataParams</span>
    <span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">dataset_root</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="n">transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">224</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># set train_params and test_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_params</span> <span class="o">=</span> <span class="n">DataParams</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">train_params</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_params</span> <span class="o">=</span> <span class="n">DataParams</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">test_params</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div><p><code>DataConfig</code> tells everything you need to know about downloading Tensorflow datasets and processing it. Agumentation information for the pipeline is based on <a href="https://albumentations.ai">albumentations</a> framework and please refer to it for additional changes. This config relays on <code>train_params</code> and <code>test_params</code> telling about shuffling and batch size for train and test splits.</p>
<h4 id="dataparams">DataParams</h4>


<div class="doc doc-object doc-class">


<a id="modules.config.DataParams"></a>
  <div class="doc doc-contents first">

  
      <p>Train and test data parameters.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>batch_size</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>batch size for training.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>shuffle</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>whether to shuffle the dataset.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>modules/config.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">DataParams</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Train and test data parameters.</span>
<span class="sd">    Arguments:</span>
<span class="sd">        batch_size (int): batch size for training.</span>
<span class="sd">        shuffle (bool): whether to shuffle the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div><h3 id="trainconfig">TrainConfig</h3>


<div class="doc doc-object doc-class">


<a id="modules.config.TrainConfig"></a>
  <div class="doc doc-contents first">

  
      <p>Configuration class to store the configuration of a train model.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model_name</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>name of the model to train. Used for saving and logging.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>model_hparams</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.config.VQGANConfig" href="../reference/#modules.config.VQGANConfig">VQGANConfig</a></code>
          </td>
          <td><p>model hyperparameters. Check VQGANConfig for more details.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>disc_hparams</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.config.DiscConfig" href="../reference/#modules.config.DiscConfig">DiscConfig</a></code>
          </td>
          <td><p>discriminator hyperparameters.
Check DiscConfig for more details.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>save_dir</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>directory to save the model.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>log_dir</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>directory to save the logs for tensorboard.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>check_val_every_n_epoch</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of epochs to run validation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>log_img_every_n_epoch</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of epochs to log images.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>input_shape</code></td>
          <td>
                <code><span title="typing.Tuple">Tuple</span>[int, int, int]</code>
          </td>
          <td><p>shape of the input image (H, W, C).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>codebook_weight</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>weight for the codebook loss (Quantizer part).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>monitor</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>metric to monitor for saving best model.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>recon_loss</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>reconstruction loss to use. Can be one of <code>l1</code>, <code>l2</code>, <code>comb</code>, <code>mape</code>.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>disc_loss</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>discriminator loss to use. Can be <code>vanilla</code> or <code>hinge</code>.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>disc_weight</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>weight for the discriminator loss.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>num_epochs</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of epochs to train.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dtype</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>dtype to use for training.
Supported: <code>float32</code>, <code>float16</code>, <code>float16</code>, <code>bfloat16</code>.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>distributed</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>whether to use distributed training.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>seed</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>seed for random number generation.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>optimizer</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>optimizer to use for training. Structure needs to be
optax Optimizer (Check optax for more details) with '<strong>target</strong>' parameter,
for specifing optax optimizer, and 'kwargs' parameter for passing to optimizer.
check config_test.yaml for example.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>optimizer_disc</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>optimizer to use for discriminator training. Similar to optimizer.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>disc_start</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of epochs to past to start using the discriminator.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>temp_scheduler</code></td>
          <td>
                <code>optional</code>
          </td>
          <td><p>temperature scheduler to use for training. Similar to optimizer
but uses optax scheduler with '<strong>target</strong>' parameter, for specifing optax scheduler.
if None, then no scheduler is used. Check config_test.yaml for example.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>modules/config.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TrainConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configuration class to store the configuration of a train model.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model_name (str): name of the model to train. Used for saving and logging.</span>
<span class="sd">        model_hparams (VQGANConfig): model hyperparameters. Check VQGANConfig for more details.</span>
<span class="sd">        disc_hparams (DiscConfig): discriminator hyperparameters.</span>
<span class="sd">            Check DiscConfig for more details.</span>
<span class="sd">        save_dir (str): directory to save the model.</span>
<span class="sd">        log_dir (str): directory to save the logs for tensorboard.</span>
<span class="sd">        check_val_every_n_epoch (int): number of epochs to run validation.</span>
<span class="sd">        log_img_every_n_epoch (int): number of epochs to log images.</span>
<span class="sd">        input_shape (Tuple[int, int, int]): shape of the input image (H, W, C).</span>
<span class="sd">        codebook_weight (float): weight for the codebook loss (Quantizer part).</span>
<span class="sd">        monitor (str): metric to monitor for saving best model.</span>
<span class="sd">        recon_loss (str): reconstruction loss to use. Can be one of `l1`, `l2`, `comb`, `mape`.</span>
<span class="sd">        disc_loss (str): discriminator loss to use. Can be `vanilla` or `hinge`.</span>
<span class="sd">        disc_weight (float): weight for the discriminator loss.</span>
<span class="sd">        num_epochs (int): number of epochs to train.</span>
<span class="sd">        dtype (str): dtype to use for training.</span>
<span class="sd">            Supported: `float32`, `float16`, `float16`, `bfloat16`.</span>
<span class="sd">        distributed (bool): whether to use distributed training.</span>
<span class="sd">        seed (int): seed for random number generation.</span>
<span class="sd">        optimizer (str): optimizer to use for training. Structure needs to be</span>
<span class="sd">            optax Optimizer (Check optax for more details) with &#39;__target__&#39; parameter,</span>
<span class="sd">            for specifing optax optimizer, and &#39;kwargs&#39; parameter for passing to optimizer.</span>
<span class="sd">            check config_test.yaml for example.</span>
<span class="sd">        optimizer_disc (str): optimizer to use for discriminator training. Similar to optimizer.</span>
<span class="sd">        disc_start (int): number of epochs to past to start using the discriminator.</span>
<span class="sd">        temp_scheduler (optional): temperature scheduler to use for training. Similar to optimizer</span>
<span class="sd">            but uses optax scheduler with &#39;__target__&#39; parameter, for specifing optax scheduler.</span>
<span class="sd">            if None, then no scheduler is used. Check config_test.yaml for example.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">model_hparams</span><span class="p">:</span> <span class="n">VQGANConfig</span>
    <span class="n">disc_hparams</span><span class="p">:</span> <span class="n">DiscConfig</span>
    <span class="n">save_dir</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">log_dir</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">check_val_every_n_epoch</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">log_img_every_n_epoch</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
    <span class="n">codebook_weight</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">monitor</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">recon_loss</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">disc_loss</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">disc_weight</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span>
    <span class="n">optimizer_disc</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span>
    <span class="n">disc_start</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">temp_scheduler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># load model hparams</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_hparams</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">VQGANConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">model_hparams</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_hparams</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">VQGANConfig</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_hparams</span><span class="p">,</span> <span class="n">VQGANConfig</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;model_hparams could not create VQGANConfig&quot;</span><span class="p">)</span>
        <span class="c1"># load disc hparams</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disc_hparams</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">DiscConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">disc_hparams</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">disc_hparams</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DiscConfig</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">disc_hparams</span><span class="p">,</span> <span class="n">DiscConfig</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;disc_hparams could not create DiscConfig&quot;</span><span class="p">)</span>
        <span class="c1"># conver shape list to tuple shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;input_shape: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="si">}</span><span class="s2"> should be of length 3&quot;</span><span class="p">)</span>
        <span class="c1"># set dtype</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;float64&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float64</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;float32&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;float16&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float16</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">bfloat16</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Invalid dtype </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"></span>
<span class="s2">                             expected one of float64, float32, float16, bfloat16&quot;&quot;&quot;</span>
            <span class="p">)</span>
        <span class="c1"># instantiate the optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">instantiate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;optimizer should be optax GradientTransformation dict to instantiate&quot;</span><span class="p">)</span>
        <span class="c1"># instantiate the optimizer for discriminator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_disc</span> <span class="o">=</span> <span class="n">instantiate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_disc</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_disc</span><span class="p">,</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;optimizer_disc should be optax GradientTransformation dict to instantiate&quot;</span>
            <span class="p">)</span>
        <span class="c1"># if optimizer is a dict, instantiate it</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">instantiate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span><span class="p">,</span> <span class="s2">&quot;__call__&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;temp_scheduler should be a callable or None&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div><p><code>TrainConfig</code> is main config for setting trainer. The most important parameters are <code>model_name</code>, <code>save_dir</code>, <code>log_dir</code>, <code>dtype</code>, <code>seed</code>, <code>distributed</code>. <code>dtype</code>, <code>seed</code> and <code>distributed</code> are parameters also used in datasets (For now we support only false for <code>distributed</code>). <code>save_dir</code> and <code>log_dir</code> are paths for model checkpointing and tensorboard saving. <code>model_name</code> is the name of model which is referenced in saving and logging to tensorboard so you need to keep an eye on this parameter. <code>optimize</code> and <code>temp_scheduler</code> are parameters which are <a href="https://hydra.cc/docs/advanced/instantiate_objects/overview/">instantiate</a> by hydra and for this we use objects from <a href="https://optax.readthedocs.io/en/latest/"><code>optax</code></a> (please refer to samples). <code>model_hparams</code> contains all the parameters for VQGAN module architecture and <code>disc_hparams</code> contains parameters for Discriminator.</p>
<h3 id="discconfig">DiscConfig</h3>


<div class="doc doc-object doc-class">


<a id="modules.config.DiscConfig"></a>
  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><span title="transformers.PretrainedConfig">PretrainedConfig</span></code></p>

  
      <p>Configuration class to store the configuration of a Discriminator model.
Dataclass for storing is based on <code>PretrainedConfig</code> from <code>transformers</code> package.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>input_last_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>last dimension of the input sample in Discriminator.</p></td>
          <td>
                <code>3</code>
          </td>
        </tr>
        <tr>
          <td><code>output_last_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>last dimension of the output sample in Discriminator.</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>resolution</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>resolution of the input image (256x256).</p></td>
          <td>
                <code>256</code>
          </td>
        </tr>
        <tr>
          <td><code>ndf</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of filters in the first layer of Discriminator.</p></td>
          <td>
                <code>64</code>
          </td>
        </tr>
        <tr>
          <td><code>n_layers</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of layers in Discriminator.</p></td>
          <td>
                <code>3</code>
          </td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>modules/config.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DiscConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Configuration class to store the configuration of a Discriminator model.</span>
<span class="sd">    Dataclass for storing is based on `PretrainedConfig` from `transformers` package.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_last_dim (int): last dimension of the input sample in Discriminator.</span>
<span class="sd">        output_last_dim (int): last dimension of the output sample in Discriminator.</span>
<span class="sd">        resolution (int): resolution of the input image (256x256).</span>
<span class="sd">        ndf (int): number of filters in the first layer of Discriminator.</span>
<span class="sd">        n_layers (int): number of layers in Discriminator.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_last_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">output_last_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">resolution</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">ndf</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_last_dim</span> <span class="o">=</span> <span class="n">input_last_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_last_dim</span> <span class="o">=</span> <span class="n">output_last_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resolution</span> <span class="o">=</span> <span class="n">resolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndf</span> <span class="o">=</span> <span class="n">ndf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div><h3 id="vqganconfig">VQGANConfig</h3>


<div class="doc doc-object doc-class">


<a id="modules.config.VQGANConfig"></a>
  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><span title="transformers.PretrainedConfig">PretrainedConfig</span></code></p>

  
      <p>Configuration class to store the configuration of a VQGAN model.
Dataclass for storing is based on <code>PretrainedConfig</code> from <code>transformers</code> package.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>ch</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of channels.</p></td>
          <td>
                <code>128</code>
          </td>
        </tr>
        <tr>
          <td><code>out_ch</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of output channels (RGB).</p></td>
          <td>
                <code>3</code>
          </td>
        </tr>
        <tr>
          <td><code>in_channels</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of input channels (RGB).</p></td>
          <td>
                <code>3</code>
          </td>
        </tr>
        <tr>
          <td><code>num_res_blocks</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of residual blocks.</p></td>
          <td>
                <code>2</code>
          </td>
        </tr>
        <tr>
          <td><code>resolution</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>resolution of the input image (256x256).</p></td>
          <td>
                <code>256</code>
          </td>
        </tr>
        <tr>
          <td><code>z_channels</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of channels in the latent space.</p></td>
          <td>
                <code>256</code>
          </td>
        </tr>
        <tr>
          <td><code>ch_mult</code></td>
          <td>
                <code><span title="typing.Tuple">Tuple</span>[int]</code>
          </td>
          <td><p>channel multiplier for each layer.</p></td>
          <td>
                <code>tuple([1, 1, 2, 2, 4])</code>
          </td>
        </tr>
        <tr>
          <td><code>attn_resolutions</code></td>
          <td>
                <code><span title="typing.Tuple">Tuple</span>[int]</code>
          </td>
          <td><p>resolutions at which to apply attention.</p></td>
          <td>
                <code>(16)</code>
          </td>
        </tr>
        <tr>
          <td><code>n_embed</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of embeddings, unique codes in the latent space.</p></td>
          <td>
                <code>1024</code>
          </td>
        </tr>
        <tr>
          <td><code>embed_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>dimension of embedding from Encoder.</p></td>
          <td>
                <code>256</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>dropout rate.</p></td>
          <td>
                <code>0.0</code>
          </td>
        </tr>
        <tr>
          <td><code>double_z</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>whether to double the latent space for.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>resamp_with_conv</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>whether to use convolutions for upsampling.</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>use_gumbel</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>whether to use gumbel softmax for quantization.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>gumb_temp</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>temperature for gumbel softmax.</p></td>
          <td>
                <code>1.0</code>
          </td>
        </tr>
        <tr>
          <td><code>act_name</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>activation function name to use.</p></td>
          <td>
                <code>&#39;swish&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>give_pre_end</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>whether to give the pre-end layer for the decoder.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>kwargs</code></td>
          <td>
                <code><span title="typing.Any">Any</span></code>
          </td>
          <td><p>keyword arguments passed along to the super class.</p></td>
          <td>
                <code>{}</code>
          </td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>modules/config.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">VQGANConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Configuration class to store the configuration of a VQGAN model.</span>
<span class="sd">    Dataclass for storing is based on `PretrainedConfig` from `transformers` package.</span>

<span class="sd">    Args:</span>
<span class="sd">        ch (int): number of channels.</span>
<span class="sd">        out_ch (int): number of output channels (RGB).</span>
<span class="sd">        in_channels (int): number of input channels (RGB).</span>
<span class="sd">        num_res_blocks (int): number of residual blocks.</span>
<span class="sd">        resolution (int): resolution of the input image (256x256).</span>
<span class="sd">        z_channels (int): number of channels in the latent space.</span>
<span class="sd">        ch_mult (Tuple[int]): channel multiplier for each layer.</span>
<span class="sd">        attn_resolutions (Tuple[int]): resolutions at which to apply attention.</span>
<span class="sd">        n_embed (int): number of embeddings, unique codes in the latent space.</span>
<span class="sd">        embed_dim (int): dimension of embedding from Encoder.</span>
<span class="sd">        dropout (float): dropout rate.</span>
<span class="sd">        double_z (bool): whether to double the latent space for.</span>
<span class="sd">        resamp_with_conv (bool): whether to use convolutions for upsampling.</span>
<span class="sd">        use_gumbel (bool): whether to use gumbel softmax for quantization.</span>
<span class="sd">        gumb_temp (float): temperature for gumbel softmax.</span>
<span class="sd">        act_name (str): activation function name to use.</span>
<span class="sd">        give_pre_end (bool): whether to give the pre-end layer for the decoder.</span>
<span class="sd">        kwargs: keyword arguments passed along to the super class.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">out_ch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">num_res_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">resolution</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">z_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">ch_mult</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
        <span class="n">attn_resolutions</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,),</span>
        <span class="n">n_embed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">double_z</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">resamp_with_conv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">use_gumbel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">gumb_temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span>
        <span class="n">kl_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-4</span><span class="p">,</span>
        <span class="n">act_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;swish&quot;</span><span class="p">,</span>
        <span class="n">give_pre_end</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ch</span> <span class="o">=</span> <span class="n">ch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_ch</span> <span class="o">=</span> <span class="n">out_ch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_res_blocks</span> <span class="o">=</span> <span class="n">num_res_blocks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resolution</span> <span class="o">=</span> <span class="n">resolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_channels</span> <span class="o">=</span> <span class="n">z_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ch_mult</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ch_mult</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_resolutions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">attn_resolutions</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_embed</span> <span class="o">=</span> <span class="n">n_embed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">double_z</span> <span class="o">=</span> <span class="n">double_z</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resamp_with_conv</span> <span class="o">=</span> <span class="n">resamp_with_conv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_gumbel</span> <span class="o">=</span> <span class="n">use_gumbel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gumb_temp</span> <span class="o">=</span> <span class="n">gumb_temp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kl_weight</span> <span class="o">=</span> <span class="n">kl_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_name</span> <span class="o">=</span> <span class="n">act_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">give_pre_end</span> <span class="o">=</span> <span class="n">give_pre_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_resolutions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ch_mult</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div><p><code>VQGANConfig</code> major parameter here is <code>use_gumbel</code>. VQGAN can be trained with <a href="https://arxiv.org/pdf/2110.01515.pdf">Gumbel-max Trick</a> (<a href="https://arxiv.org/pdf/1611.01144.pdf">Original paper</a>) which gives our bottleneck distribution on which we choose argmax for the code to assign.</p>
<h2 id="samples">Samples</h2>
<p>We provide three samples of data and train configs:
- <a href="https://github.com/WolodjaZ/jax-vqgan/blob/main/conf/config.yaml"><code>config.yaml</code></a> my training config on <code>imagenette</code> dataset.
- <a href="https://github.com/WolodjaZ/jax-vqgan/blob/main/conf/gumbel.yaml"><code>gumbel.yaml</code></a> official training config on <code>imagenet</code> dataset.
- <a href="https://github.com/WolodjaZ/jax-vqgan/blob/main/conf/imagenet.yaml"><code>imagenet.yaml</code></a> official training config with Gumble tick on <code>imagenet</code> dataset.</p>
<h2 id="major-modules">Major Modules</h2>
<p>Major Modules used in the pipeline are:</p>
<h3 id="trainervqgan">TrainerVQGan</h3>
<p><code>TrainerVQGan</code> in <a href="https://github.com/WolodjaZ/jax-vqgan/blob/e67c52cbb02fc39fbbfacc1ad06f40e6a7d53a79/modules/training.py#L329"><code>modules.training</code></a>, this modules responds for training VQGAN</p>


<div class="doc doc-object doc-class">


<a id="modules.training.TrainerVQGan"></a>
  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="modules.training.TrainerModule" href="../reference/#modules.training.TrainerModule">TrainerModule</a></code></p>

  
      <p>Helper functions for training VQGAN.</p>


        <details class="quote">
          <summary>Source code in <code>modules/training.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TrainerVQGan</span><span class="p">(</span><span class="n">TrainerModule</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper functions for training VQGAN.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_config</span><span class="p">:</span> <span class="n">config</span><span class="o">.</span><span class="n">TrainConfig</span><span class="p">):</span>
        <span class="c1"># Initialize parent class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span> <span class="o">=</span> <span class="n">module_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">model_name</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">recon_loss</span> <span class="o">==</span> <span class="s2">&quot;l2&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss_fn</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">l2_loss</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">recon_loss</span> <span class="o">==</span> <span class="s2">&quot;l1&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss_fn</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">l1_loss</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">recon_loss</span> <span class="o">==</span> <span class="s2">&quot;combo&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss_fn</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">combo_loss</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">recon_loss</span> <span class="o">==</span> <span class="s2">&quot;mape&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss_fn</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">mape_loss</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Reconstruction loss function </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">recon_loss</span><span class="si">}</span><span class="s2"> not supported.</span>
<span class="s2">                Will be used default l1 loss instead.&quot;&quot;&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss_fn</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">l1_loss</span>
        <span class="c1"># Train state for discriminator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="p">:</span> <span class="n">FlaxPreTrainedModel</span> <span class="o">=</span> <span class="n">vqgan</span><span class="o">.</span><span class="n">VQGanDiscriminator</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_hparams</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_loss</span> <span class="o">==</span> <span class="s2">&quot;vanilla&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disc_loss_fn</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">disc_loss_vanilla</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_loss</span> <span class="o">==</span> <span class="s2">&quot;hinge&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disc_loss_fn</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">disc_loss_hinge</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Discriminator loss function </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_loss</span><span class="si">}</span><span class="s2"> not supported.</span>
<span class="s2">                Will be used default hinge loss instead.&quot;&quot;&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disc_loss_fn</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">disc_loss_hinge</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span> <span class="o">=</span> <span class="n">TrainStateDisc</span><span class="p">(</span>
            <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">apply_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="fm">__call__</span><span class="p">,</span>
            <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">],</span>
            <span class="n">batch_stats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">],</span>
            <span class="n">tx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">opt_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Log dir discriminator loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_dir_disc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_disc/&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">temp_scheduler</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module_config</span><span class="o">=</span><span class="n">module_config</span><span class="p">,</span> <span class="n">model_class</span><span class="o">=</span><span class="n">vqgan</span><span class="o">.</span><span class="n">VQModel</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">temperature_scheduling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Temperature scheduling.</span>
<span class="sd">        Args:</span>
<span class="sd">            epoch (int): Current epoch.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Temperature.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_temperature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">model_hparams</span><span class="o">.</span><span class="n">gumb_temp</span>

    <span class="k">def</span> <span class="nf">init_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize optimizer and scheduler also for discriminator.</span>
<span class="sd">        By default, we decrease the learning rate with cosine annealing.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="n">optimizer_disc</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">optimizer_disc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_train_stat_full</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_disc</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_train_stat_full</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span><span class="p">,</span>
        <span class="n">optimizer_disc</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize training state.</span>
<span class="sd">        Args:</span>
<span class="sd">            optimizer (optax.GradientTransformation): Optimizer for generator.</span>
<span class="sd">            optimizer_disc (optax.GradientTransformation): Optimizer for discriminator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">apply_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">tx</span><span class="o">=</span><span class="n">optimizer</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span> <span class="o">=</span> <span class="n">TrainStateDisc</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">apply_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span>
            <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
            <span class="n">batch_stats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">batch_stats</span><span class="p">,</span>
            <span class="n">tx</span><span class="o">=</span><span class="n">optimizer_disc</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save current model.</span>
<span class="sd">        Args:</span>
<span class="sd">            step (int, optional): Current step. Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">step</span> <span class="o">=</span> <span class="n">step</span> <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">num_epochs</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
        <span class="n">checkpoints</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span>
            <span class="n">ckpt_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir_disc</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load model.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">checkpoints</span><span class="o">.</span><span class="n">restore_checkpoint</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir_disc</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span> <span class="o">=</span> <span class="n">TrainStateDisc</span><span class="p">(</span>
            <span class="n">apply_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span>
            <span class="n">params</span><span class="o">=</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">],</span>
            <span class="n">batch_stats</span><span class="o">=</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">],</span>
            <span class="n">step</span><span class="o">=</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">],</span>
            <span class="n">tx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">tx</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">tx</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">optimizer_disc</span><span class="p">,</span>
            <span class="n">opt_state</span><span class="o">=</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;opt_state&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">batch_stats</span>

    <span class="k">def</span> <span class="nf">checkpoint_exists</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Check whether a pretrained model exist.</span>
<span class="sd">        Returns:</span>
<span class="sd">            True if model and discriminator exists, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">main_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">disc_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir_disc</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">main_model</span> <span class="ow">and</span> <span class="n">disc_model</span>

    <span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">:</span> <span class="n">utils</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Train model for one epoch, and log avg metrics.</span>
<span class="sd">        Args:</span>
<span class="sd">            data_loader (utils.DataLoader): Data loader to train on.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Dictionary with all metrics.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">metrics_disc</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">metrics_disc</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">new_temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature_scheduling</span><span class="p">(</span><span class="n">epoch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">data_loader</span><span class="p">(),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">batch_metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
            <span class="n">train_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
                <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
                <span class="n">disc_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span>
                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                <span class="n">rng</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">main_rng</span><span class="p">,</span>
                <span class="n">optimizer_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">disc_use</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_start</span> <span class="o">&gt;</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_rng</span><span class="p">,</span> <span class="n">batch_metrics</span> <span class="o">=</span> <span class="n">train_outs</span>
            <span class="c1"># Update metrics</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">value</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_start</span> <span class="o">&gt;</span> <span class="n">epoch</span><span class="p">:</span>
                <span class="n">batch_metrics_disc</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
                <span class="n">train_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
                    <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
                    <span class="n">disc_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span>
                    <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                    <span class="n">rng</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">main_rng</span><span class="p">,</span>
                    <span class="n">optimizer_idx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">disc_use</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_rng</span><span class="p">,</span> <span class="n">batch_metrics_disc</span> <span class="o">=</span> <span class="n">train_outs</span>
                <span class="c1"># Update metrics discriminator</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_metrics_disc</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">metrics_disc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">value</span>
                <span class="n">metrics_disc</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">1.0</span>

            <span class="c1"># ensure that model have actual parameters</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">params</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">params</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">batch_stats</span>

        <span class="n">count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="n">count</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">}</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;temp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_temp</span>
        <span class="n">count_disc</span> <span class="o">=</span> <span class="n">metrics_disc</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">metrics_disc</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span>
        <span class="n">metrics_disc_resized</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">metrics_disc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="n">count_disc</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metrics_disc</span>
        <span class="p">}</span>
        <span class="c1"># merge metrics</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics_disc_resized</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">create_functions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create training and eval functions.&quot;&quot;&quot;</span>
        <span class="n">recon_loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss_fn</span>
        <span class="n">disc_loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">disc_loss_fn</span>

        <span class="k">def</span> <span class="nf">calculate_loss_autoencoder</span><span class="p">(</span>
            <span class="n">params</span><span class="p">:</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
            <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
            <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
            <span class="n">disc_variables</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]:</span>
            <span class="sd">&quot;&quot;&quot;Function to calculate the loss autoencoder for a batch of images.&quot;&quot;&quot;</span>
            <span class="n">new_rng</span><span class="p">,</span> <span class="n">gumble_apply_rng</span><span class="p">,</span> <span class="n">dropout_apply_rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
                <span class="n">batch</span><span class="p">,</span>
                <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                <span class="n">dropout_rng</span><span class="o">=</span><span class="n">dropout_apply_rng</span><span class="p">,</span>
                <span class="n">gumble_rng</span><span class="o">=</span><span class="n">gumble_apply_rng</span><span class="p">,</span>
                <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">x_recon</span><span class="p">,</span> <span class="n">z_q</span><span class="p">,</span> <span class="n">codebook_loss</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">outs</span>
            <span class="c1"># for now we will use l1 loss than it will be combined with perceptual loss</span>
            <span class="n">rec_loss</span> <span class="o">=</span> <span class="n">recon_loss_fn</span><span class="p">(</span><span class="n">x_recon</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">nll_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rec_loss</span><span class="p">)</span>

            <span class="c1"># Generator loss (autoencode)</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="p">(</span>
                <span class="n">x_recon</span><span class="p">,</span>
                <span class="n">params</span><span class="o">=</span><span class="n">disc_variables</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
                <span class="n">batch_stats</span><span class="o">=</span><span class="n">disc_variables</span><span class="o">.</span><span class="n">batch_stats</span><span class="p">,</span>
                <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logits_fake</span><span class="p">,</span> <span class="n">new_model_state</span> <span class="o">=</span> <span class="n">outs</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="c1"># Original loss is</span>
            <span class="c1"># g_loss = -jnp.mean(logits_fake)</span>
            <span class="c1"># But we think that based on disc for generator should work we will use minimax loss</span>
            <span class="c1"># This loss is none negative and tries to maximize the probability of the fake_logits.</span>
            <span class="n">g_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">logits_fake</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">))</span>
            <span class="n">disc_factor</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">if</span> <span class="n">disc_use</span><span class="p">:</span>
                <span class="n">disc_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_weight</span>
            <span class="n">disc_factor</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
                <span class="n">disc_use</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_weight</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">nll_loss</span>
                <span class="o">+</span> <span class="n">disc_factor</span> <span class="o">*</span> <span class="n">g_loss</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">codebook_weight</span> <span class="o">*</span> <span class="n">codebook_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;total_loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
                <span class="s2">&quot;quant_loss&quot;</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">codebook_loss</span><span class="p">),</span>
                <span class="s2">&quot;nll_loss&quot;</span><span class="p">:</span> <span class="n">nll_loss</span><span class="p">,</span>
                <span class="s2">&quot;rec_loss&quot;</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rec_loss</span><span class="p">),</span>
                <span class="s2">&quot;g_loss&quot;</span><span class="p">:</span> <span class="n">g_loss</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">new_model_state</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">calculate_loss_disc</span><span class="p">(</span>
            <span class="n">params</span><span class="p">:</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
            <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
            <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
            <span class="n">batch_stats</span><span class="p">:</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
            <span class="n">model_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]:</span>
            <span class="sd">&quot;&quot;&quot;Function to calculate the loss discriminator for a batch of images.&quot;&quot;&quot;</span>
            <span class="n">new_rng</span><span class="p">,</span> <span class="n">gumble_apply_rng</span><span class="p">,</span> <span class="n">dropout_apply_rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
                <span class="n">batch</span><span class="p">,</span>
                <span class="n">params</span><span class="o">=</span><span class="n">model_params</span><span class="p">,</span>
                <span class="n">dropout_rng</span><span class="o">=</span><span class="n">dropout_apply_rng</span><span class="p">,</span>
                <span class="n">gumble_rng</span><span class="o">=</span><span class="n">gumble_apply_rng</span><span class="p">,</span>
                <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">x_recon</span><span class="p">,</span> <span class="n">z_q</span><span class="p">,</span> <span class="n">codebook_loss</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">outs</span>

            <span class="c1"># Discriminator loss</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_stats</span><span class="o">=</span><span class="n">batch_stats</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
            <span class="n">logits_real</span><span class="p">,</span> <span class="n">new_model_state</span> <span class="o">=</span> <span class="n">outs</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="p">(</span><span class="n">x_recon</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_stats</span><span class="o">=</span><span class="n">batch_stats</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
            <span class="n">logits_fake</span><span class="p">,</span> <span class="n">new_model_state</span> <span class="o">=</span> <span class="n">outs</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">disc_factor</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
                <span class="n">disc_use</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_weight</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">disc_factor</span> <span class="o">*</span> <span class="n">disc_loss_fn</span><span class="p">(</span><span class="n">logits_real</span><span class="p">,</span> <span class="n">logits_fake</span><span class="p">)</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;disc_loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
                <span class="s2">&quot;logits_real&quot;</span><span class="p">:</span> <span class="n">logits_real</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                <span class="s2">&quot;logits_fake&quot;</span><span class="p">:</span> <span class="n">logits_fake</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
            <span class="p">}</span>

            <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">new_model_state</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">train_step_autoencoder</span><span class="p">(</span>
            <span class="n">state</span><span class="p">:</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span>
            <span class="n">disc_state</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
            <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
            <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
            <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span> <span class="n">TrainStateDisc</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
        <span class="p">]:</span>
            <span class="sd">&quot;&quot;&quot;Train step for autoencoder.&quot;&quot;&quot;</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">calculate_loss_autoencoder</span><span class="p">,</span>
                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
                <span class="n">disc_use</span><span class="o">=</span><span class="n">disc_use</span><span class="p">,</span>
                <span class="n">disc_variables</span><span class="o">=</span><span class="n">disc_state</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">new_model_state</span><span class="p">)),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span>
                <span class="n">loss_fn</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)(</span><span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
            <span class="c1"># if distributed training, average grads</span>
            <span class="k">if</span> <span class="n">distributed</span><span class="p">:</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">pmean</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span>
            <span class="c1"># Update parameters</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span>

        <span class="k">def</span> <span class="nf">train_step_disc</span><span class="p">(</span>
            <span class="n">state</span><span class="p">:</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span>
            <span class="n">disc_state</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
            <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
            <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
            <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span> <span class="n">TrainStateDisc</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
        <span class="p">]:</span>
            <span class="sd">&quot;&quot;&quot;Train step for discriminator.&quot;&quot;&quot;</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">calculate_loss_disc</span><span class="p">,</span>
                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
                <span class="n">disc_use</span><span class="o">=</span><span class="n">disc_use</span><span class="p">,</span>
                <span class="n">batch_stats</span><span class="o">=</span><span class="n">disc_state</span><span class="o">.</span><span class="n">batch_stats</span><span class="p">,</span>
                <span class="n">model_params</span><span class="o">=</span><span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">new_model_state</span><span class="p">)),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span>
                <span class="n">loss_fn</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)(</span><span class="n">disc_state</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
            <span class="c1"># if distributed training, average grads</span>
            <span class="k">if</span> <span class="n">distributed</span><span class="p">:</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">pmean</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span>
            <span class="c1"># Update parameters, batch statistics</span>
            <span class="n">disc_state</span> <span class="o">=</span> <span class="n">disc_state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
                <span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">,</span> <span class="n">batch_stats</span><span class="o">=</span><span class="n">new_model_state</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span>

        <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
            <span class="n">state</span><span class="p">:</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span>
            <span class="n">disc_state</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
            <span class="n">optimizer_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
            <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
            <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span> <span class="n">TrainStateDisc</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
        <span class="p">]:</span>
            <span class="sd">&quot;&quot;&quot;Train model on a single batch.&quot;&quot;&quot;</span>
            <span class="c1"># calculate loss</span>
            <span class="k">if</span> <span class="n">optimizer_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">outs</span> <span class="o">=</span> <span class="n">train_step_autoencoder</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">disc_use</span><span class="p">,</span> <span class="n">distributed</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outs</span> <span class="o">=</span> <span class="n">train_step_disc</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">disc_use</span><span class="p">,</span> <span class="n">distributed</span><span class="p">)</span>
            <span class="c1"># outs = jax.lax.cond(</span>
            <span class="c1">#  optimizer_idx == 0,</span>
            <span class="c1">#    lambda _: train_step_autoencoder(state,</span>
            <span class="c1">#                                     disc_state,</span>
            <span class="c1">#                                     batch,</span>
            <span class="c1">#                                     rng,</span>
            <span class="c1">#                                     disc_use,</span>
            <span class="c1">#                                     distributed),</span>
            <span class="c1">#    lambda _: train_step_disc(state,</span>
            <span class="c1">#                              disc_state,</span>
            <span class="c1">#                              batch,</span>
            <span class="c1">#                              rng,</span>
            <span class="c1">#                              disc_use,</span>
            <span class="c1">#                              distributed),</span>
            <span class="c1">#    None)</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="n">outs</span>
            <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span>

        <span class="k">def</span> <span class="nf">eval_step</span><span class="p">(</span>
            <span class="n">state</span><span class="p">:</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
            <span class="n">disc_state</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
            <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
            <span class="sd">&quot;&quot;&quot;Evaluate model on a single batch.&quot;&quot;&quot;</span>
            <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">calculate_loss_autoencoder</span><span class="p">(</span>
                <span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
                <span class="n">disc_use</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">disc_variables</span><span class="o">=</span><span class="n">disc_state</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span>

        <span class="c1"># pmap or jit for efficiency</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">pmap</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
                <span class="n">train_step</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">static_broadcasted_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_step</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">eval_step</span><span class="p">,</span> <span class="n">disc_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">))</span>  <span class="c1"># type: ignore</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># type: ignore</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_step</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">eval_step</span><span class="p">,</span> <span class="n">disc_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">))</span>  <span class="c1"># type: ignore</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h2 id="modules.training.TrainerVQGan.checkpoint_exists" class="doc doc-heading">
<code class="highlight language-python"><span class="n">checkpoint_exists</span><span class="p">()</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Check whether a pretrained model exist.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>bool</code>
          </td>
          <td><p>True if model and discriminator exists, False otherwise.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/training.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">checkpoint_exists</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Check whether a pretrained model exist.</span>
<span class="sd">    Returns:</span>
<span class="sd">        True if model and discriminator exists, False otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">main_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">disc_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir_disc</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">main_model</span> <span class="ow">and</span> <span class="n">disc_model</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.training.TrainerVQGan.create_functions" class="doc doc-heading">
<code class="highlight language-python"><span class="n">create_functions</span><span class="p">()</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Create training and eval functions.</p>

      <details class="quote">
        <summary>Source code in <code>modules/training.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_functions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create training and eval functions.&quot;&quot;&quot;</span>
    <span class="n">recon_loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recon_loss_fn</span>
    <span class="n">disc_loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">disc_loss_fn</span>

    <span class="k">def</span> <span class="nf">calculate_loss_autoencoder</span><span class="p">(</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">disc_variables</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Function to calculate the loss autoencoder for a batch of images.&quot;&quot;&quot;</span>
        <span class="n">new_rng</span><span class="p">,</span> <span class="n">gumble_apply_rng</span><span class="p">,</span> <span class="n">dropout_apply_rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">batch</span><span class="p">,</span>
            <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
            <span class="n">dropout_rng</span><span class="o">=</span><span class="n">dropout_apply_rng</span><span class="p">,</span>
            <span class="n">gumble_rng</span><span class="o">=</span><span class="n">gumble_apply_rng</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">x_recon</span><span class="p">,</span> <span class="n">z_q</span><span class="p">,</span> <span class="n">codebook_loss</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">outs</span>
        <span class="c1"># for now we will use l1 loss than it will be combined with perceptual loss</span>
        <span class="n">rec_loss</span> <span class="o">=</span> <span class="n">recon_loss_fn</span><span class="p">(</span><span class="n">x_recon</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="n">nll_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rec_loss</span><span class="p">)</span>

        <span class="c1"># Generator loss (autoencode)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="p">(</span>
            <span class="n">x_recon</span><span class="p">,</span>
            <span class="n">params</span><span class="o">=</span><span class="n">disc_variables</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
            <span class="n">batch_stats</span><span class="o">=</span><span class="n">disc_variables</span><span class="o">.</span><span class="n">batch_stats</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logits_fake</span><span class="p">,</span> <span class="n">new_model_state</span> <span class="o">=</span> <span class="n">outs</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="c1"># Original loss is</span>
        <span class="c1"># g_loss = -jnp.mean(logits_fake)</span>
        <span class="c1"># But we think that based on disc for generator should work we will use minimax loss</span>
        <span class="c1"># This loss is none negative and tries to maximize the probability of the fake_logits.</span>
        <span class="n">g_loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">logits_fake</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">))</span>
        <span class="n">disc_factor</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="n">disc_use</span><span class="p">:</span>
            <span class="n">disc_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_weight</span>
        <span class="n">disc_factor</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
            <span class="n">disc_use</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_weight</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">nll_loss</span>
            <span class="o">+</span> <span class="n">disc_factor</span> <span class="o">*</span> <span class="n">g_loss</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">codebook_weight</span> <span class="o">*</span> <span class="n">codebook_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;total_loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s2">&quot;quant_loss&quot;</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">codebook_loss</span><span class="p">),</span>
            <span class="s2">&quot;nll_loss&quot;</span><span class="p">:</span> <span class="n">nll_loss</span><span class="p">,</span>
            <span class="s2">&quot;rec_loss&quot;</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rec_loss</span><span class="p">),</span>
            <span class="s2">&quot;g_loss&quot;</span><span class="p">:</span> <span class="n">g_loss</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">new_model_state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">calculate_loss_disc</span><span class="p">(</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">batch_stats</span><span class="p">:</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">model_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Function to calculate the loss discriminator for a batch of images.&quot;&quot;&quot;</span>
        <span class="n">new_rng</span><span class="p">,</span> <span class="n">gumble_apply_rng</span><span class="p">,</span> <span class="n">dropout_apply_rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">batch</span><span class="p">,</span>
            <span class="n">params</span><span class="o">=</span><span class="n">model_params</span><span class="p">,</span>
            <span class="n">dropout_rng</span><span class="o">=</span><span class="n">dropout_apply_rng</span><span class="p">,</span>
            <span class="n">gumble_rng</span><span class="o">=</span><span class="n">gumble_apply_rng</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">x_recon</span><span class="p">,</span> <span class="n">z_q</span><span class="p">,</span> <span class="n">codebook_loss</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">outs</span>

        <span class="c1"># Discriminator loss</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_stats</span><span class="o">=</span><span class="n">batch_stats</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
        <span class="n">logits_real</span><span class="p">,</span> <span class="n">new_model_state</span> <span class="o">=</span> <span class="n">outs</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="p">(</span><span class="n">x_recon</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_stats</span><span class="o">=</span><span class="n">batch_stats</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
        <span class="n">logits_fake</span><span class="p">,</span> <span class="n">new_model_state</span> <span class="o">=</span> <span class="n">outs</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">disc_factor</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
            <span class="n">disc_use</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_weight</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">disc_factor</span> <span class="o">*</span> <span class="n">disc_loss_fn</span><span class="p">(</span><span class="n">logits_real</span><span class="p">,</span> <span class="n">logits_fake</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;disc_loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s2">&quot;logits_real&quot;</span><span class="p">:</span> <span class="n">logits_real</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
            <span class="s2">&quot;logits_fake&quot;</span><span class="p">:</span> <span class="n">logits_fake</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">new_model_state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_step_autoencoder</span><span class="p">(</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span>
        <span class="n">disc_state</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span> <span class="n">TrainStateDisc</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
    <span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Train step for autoencoder.&quot;&quot;&quot;</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">calculate_loss_autoencoder</span><span class="p">,</span>
            <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
            <span class="n">disc_use</span><span class="o">=</span><span class="n">disc_use</span><span class="p">,</span>
            <span class="n">disc_variables</span><span class="o">=</span><span class="n">disc_state</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">new_model_state</span><span class="p">)),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span>
            <span class="n">loss_fn</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)(</span><span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="c1"># if distributed training, average grads</span>
        <span class="k">if</span> <span class="n">distributed</span><span class="p">:</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">pmean</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span>
        <span class="c1"># Update parameters</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">train_step_disc</span><span class="p">(</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span>
        <span class="n">disc_state</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span> <span class="n">TrainStateDisc</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
    <span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Train step for discriminator.&quot;&quot;&quot;</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">calculate_loss_disc</span><span class="p">,</span>
            <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
            <span class="n">disc_use</span><span class="o">=</span><span class="n">disc_use</span><span class="p">,</span>
            <span class="n">batch_stats</span><span class="o">=</span><span class="n">disc_state</span><span class="o">.</span><span class="n">batch_stats</span><span class="p">,</span>
            <span class="n">model_params</span><span class="o">=</span><span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">new_model_state</span><span class="p">)),</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span>
            <span class="n">loss_fn</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)(</span><span class="n">disc_state</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="c1"># if distributed training, average grads</span>
        <span class="k">if</span> <span class="n">distributed</span><span class="p">:</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">pmean</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span>
        <span class="c1"># Update parameters, batch statistics</span>
        <span class="n">disc_state</span> <span class="o">=</span> <span class="n">disc_state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
            <span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">,</span> <span class="n">batch_stats</span><span class="o">=</span><span class="n">new_model_state</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span>
        <span class="n">disc_state</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">optimizer_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">disc_use</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span> <span class="n">TrainStateDisc</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
    <span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Train model on a single batch.&quot;&quot;&quot;</span>
        <span class="c1"># calculate loss</span>
        <span class="k">if</span> <span class="n">optimizer_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="n">train_step_autoencoder</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">disc_use</span><span class="p">,</span> <span class="n">distributed</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="n">train_step_disc</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">disc_use</span><span class="p">,</span> <span class="n">distributed</span><span class="p">)</span>
        <span class="c1"># outs = jax.lax.cond(</span>
        <span class="c1">#  optimizer_idx == 0,</span>
        <span class="c1">#    lambda _: train_step_autoencoder(state,</span>
        <span class="c1">#                                     disc_state,</span>
        <span class="c1">#                                     batch,</span>
        <span class="c1">#                                     rng,</span>
        <span class="c1">#                                     disc_use,</span>
        <span class="c1">#                                     distributed),</span>
        <span class="c1">#    lambda _: train_step_disc(state,</span>
        <span class="c1">#                              disc_state,</span>
        <span class="c1">#                              batch,</span>
        <span class="c1">#                              rng,</span>
        <span class="c1">#                              disc_use,</span>
        <span class="c1">#                              distributed),</span>
        <span class="c1">#    None)</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="n">outs</span>
        <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">disc_state</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">eval_step</span><span class="p">(</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">disc_state</span><span class="p">:</span> <span class="n">TrainStateDisc</span><span class="p">,</span>
        <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Evaluate model on a single batch.&quot;&quot;&quot;</span>
        <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">calculate_loss_autoencoder</span><span class="p">(</span>
            <span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
            <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
            <span class="n">disc_use</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">disc_variables</span><span class="o">=</span><span class="n">disc_state</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">new_rng</span><span class="p">,</span> <span class="n">metrics</span>

    <span class="c1"># pmap or jit for efficiency</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">pmap</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
            <span class="n">train_step</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">static_broadcasted_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_step</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">eval_step</span><span class="p">,</span> <span class="n">disc_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">))</span>  <span class="c1"># type: ignore</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">train_step</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># type: ignore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_step</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">eval_step</span><span class="p">,</span> <span class="n">disc_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">))</span>  <span class="c1"># type: ignore</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.training.TrainerVQGan.create_train_stat_full" class="doc doc-heading">
<code class="highlight language-python"><span class="n">create_train_stat_full</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_disc</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Initialize training state.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>optimizer</code></td>
          <td>
                <code>optax.<span title="optax.GradientTransformation">GradientTransformation</span></code>
          </td>
          <td><p>Optimizer for generator.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>optimizer_disc</code></td>
          <td>
                <code>optax.<span title="optax.GradientTransformation">GradientTransformation</span></code>
          </td>
          <td><p>Optimizer for discriminator.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/training.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_train_stat_full</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span><span class="p">,</span>
    <span class="n">optimizer_disc</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialize training state.</span>
<span class="sd">    Args:</span>
<span class="sd">        optimizer (optax.GradientTransformation): Optimizer for generator.</span>
<span class="sd">        optimizer_disc (optax.GradientTransformation): Optimizer for discriminator.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">apply_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">tx</span><span class="o">=</span><span class="n">optimizer</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span> <span class="o">=</span> <span class="n">TrainStateDisc</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">apply_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
        <span class="n">batch_stats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">batch_stats</span><span class="p">,</span>
        <span class="n">tx</span><span class="o">=</span><span class="n">optimizer_disc</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.training.TrainerVQGan.init_optimizer" class="doc doc-heading">
<code class="highlight language-python"><span class="n">init_optimizer</span><span class="p">()</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Initialize optimizer and scheduler also for discriminator.
By default, we decrease the learning rate with cosine annealing.</p>

      <details class="quote">
        <summary>Source code in <code>modules/training.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">init_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialize optimizer and scheduler also for discriminator.</span>
<span class="sd">    By default, we decrease the learning rate with cosine annealing.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">optimizer</span>
    <span class="n">optimizer_disc</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">GradientTransformation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">optimizer_disc</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">create_train_stat_full</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_disc</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.training.TrainerVQGan.load_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load_model</span><span class="p">()</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Load model.</p>

      <details class="quote">
        <summary>Source code in <code>modules/training.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Load model.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">checkpoints</span><span class="o">.</span><span class="n">restore_checkpoint</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir_disc</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span> <span class="o">=</span> <span class="n">TrainStateDisc</span><span class="p">(</span>
        <span class="n">apply_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">],</span>
        <span class="n">batch_stats</span><span class="o">=</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">],</span>
        <span class="n">step</span><span class="o">=</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">],</span>
        <span class="n">tx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">tx</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">tx</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">optimizer_disc</span><span class="p">,</span>
        <span class="n">opt_state</span><span class="o">=</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;opt_state&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">batch_stats</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.training.TrainerVQGan.save_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save_model</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Save current model.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>step</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Current step. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/training.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Save current model.</span>
<span class="sd">    Args:</span>
<span class="sd">        step (int, optional): Current step. Defaults to None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">step</span> <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">num_epochs</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
    <span class="n">checkpoints</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span>
        <span class="n">ckpt_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir_disc</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.training.TrainerVQGan.temperature_scheduling" class="doc doc-heading">
<code class="highlight language-python"><span class="n">temperature_scheduling</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Temperature scheduling.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>epoch</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Current epoch.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>float</code>
          </td>
          <td><p>Temperature.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/training.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">temperature_scheduling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Temperature scheduling.</span>
<span class="sd">    Args:</span>
<span class="sd">        epoch (int): Current epoch.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Temperature.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update_temperature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temp_scheduler</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">model_hparams</span><span class="o">.</span><span class="n">gumb_temp</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.training.TrainerVQGan.train_epoch" class="doc doc-heading">
<code class="highlight language-python"><span class="n">train_epoch</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Train model for one epoch, and log avg metrics.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>data_loader</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.utils" href="../reference/#modules.utils">utils</a>.<a class="autorefs autorefs-internal" title="modules.utils.DataLoader" href="../reference/#modules.utils.DataLoader">DataLoader</a></code>
          </td>
          <td><p>Data loader to train on.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, float]</code>
          </td>
          <td><p>Dictionary with all metrics.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/training.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">:</span> <span class="n">utils</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Train model for one epoch, and log avg metrics.</span>
<span class="sd">    Args:</span>
<span class="sd">        data_loader (utils.DataLoader): Data loader to train on.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Dictionary with all metrics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">metrics_disc</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">metrics_disc</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">new_temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature_scheduling</span><span class="p">(</span><span class="n">epoch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">data_loader</span><span class="p">(),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">batch_metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
        <span class="n">train_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
            <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
            <span class="n">disc_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span>
            <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
            <span class="n">rng</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">main_rng</span><span class="p">,</span>
            <span class="n">optimizer_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">disc_use</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_start</span> <span class="o">&gt;</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_rng</span><span class="p">,</span> <span class="n">batch_metrics</span> <span class="o">=</span> <span class="n">train_outs</span>
        <span class="c1"># Update metrics</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">value</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">disc_start</span> <span class="o">&gt;</span> <span class="n">epoch</span><span class="p">:</span>
            <span class="n">batch_metrics_disc</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
            <span class="n">train_outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_step</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
                <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
                <span class="n">disc_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span>
                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                <span class="n">rng</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">main_rng</span><span class="p">,</span>
                <span class="n">optimizer_idx</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">disc_use</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module_config</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_rng</span><span class="p">,</span> <span class="n">batch_metrics_disc</span> <span class="o">=</span> <span class="n">train_outs</span>
            <span class="c1"># Update metrics discriminator</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_metrics_disc</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">metrics_disc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">value</span>
            <span class="n">metrics_disc</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">1.0</span>

        <span class="c1"># ensure that model have actual parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_disc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_disc</span><span class="o">.</span><span class="n">batch_stats</span>

    <span class="n">count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="n">count</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">}</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;temp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_temp</span>
    <span class="n">count_disc</span> <span class="o">=</span> <span class="n">metrics_disc</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span>
    <span class="k">del</span> <span class="n">metrics_disc</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">]</span>
    <span class="n">metrics_disc_resized</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">metrics_disc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="n">count_disc</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metrics_disc</span>
    <span class="p">}</span>
    <span class="c1"># merge metrics</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics_disc_resized</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div><h3 id="vqganpretrainedmodel">VQGANPreTrainedModel</h3>
<p><code>VQGANPreTrainedModel</code> in <a href="https://github.com/WolodjaZ/jax-vqgan/blob/e67c52cbb02fc39fbbfacc1ad06f40e6a7d53a79/modules/vqgan.py#L322"><code>modules.vqgan</code></a>, response for VQ autoencoder architecture. This class is based on <code>FlaxPreTrainedModel</code> which gives ous abilities to push the architecture to Hugging Face Hub.</p>


<div class="doc doc-object doc-class">


<a id="modules.vqgan.VQGANPreTrainedModel"></a>
  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><span title="transformers.modeling_flax_utils.FlaxPreTrainedModel">FlaxPreTrainedModel</span></code></p>

  
      <p>An abstract class to handle weights initialization and a simple interface
for downloading and loading pretrained models.</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>module_class</code></td>
          <td>
                <code><span title="flax.linen">nn</span>.<span title="flax.linen.Module">Module</span></code>
          </td>
          <td><p>a class derived from nn.Module
that defines the model's core computation.</p></td>
        </tr>
        <tr>
          <td><code>config_class</code></td>
          <td>
                <code><span title="transformers.PretrainedConfig">PretrainedConfig</span></code>
          </td>
          <td><p>a class derived from PretrainedConfig</p></td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>modules/vqgan.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">VQGANPreTrainedModel</span><span class="p">(</span><span class="n">FlaxPreTrainedModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;An abstract class to handle weights initialization and a simple interface</span>
<span class="sd">    for downloading and loading pretrained models.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        module_class (nn.Module): a class derived from nn.Module</span>
<span class="sd">            that defines the model&#39;s core computation.</span>
<span class="sd">        config_class (PretrainedConfig): a class derived from PretrainedConfig</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">module_class</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
    <span class="n">config_class</span><span class="p">:</span> <span class="n">PretrainedConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">PretrainedConfig</span> <span class="o">=</span> <span class="n">VQGANConfig</span><span class="p">(),</span>
        <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">_do_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            config (PretrainedConfig, optional): the config of the model. Defaults to VQGANConfig.</span>
<span class="sd">            input_shape (Tuple, optional): the input shape of the model.</span>
<span class="sd">                Defaults to (1, 256, 256, 3).</span>
<span class="sd">            seed (int, optional): the seed of the model. Defaults to 0.</span>
<span class="sd">            dtype (jnp.dtype, optional): the dtype of the computation. Defaults to jnp.float32.</span>
<span class="sd">            _do_init (bool, optional): whether to initialize the model. Defaults to True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config_class</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2"> has to be an instance of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config_class</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;module_class should be defined in derived classes&quot;</span><span class="p">)</span>
        <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_class</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">config</span><span class="p">,</span>
            <span class="n">module</span><span class="p">,</span>
            <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">_do_init</span><span class="o">=</span><span class="n">_do_init</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Initialize the weights of the model. Get the params</span>

<span class="sd">        Args:</span>
<span class="sd">            rng (Union[Any,jnp.ndarray]): the random number generator.</span>
<span class="sd">            input_shape (Tuple): the input shape of the model.</span>
<span class="sd">            params (FrozenDict, optional): the params of the model. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            initialized params of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># initialize model</span>
        <span class="n">input_x</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">params_rng</span><span class="p">,</span> <span class="n">dropout_rng</span><span class="p">,</span> <span class="n">gumble_rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">rngs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params_rng</span><span class="p">,</span>
            <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout_rng</span><span class="p">,</span>
            <span class="s2">&quot;gumbel&quot;</span><span class="p">:</span> <span class="n">gumble_rng</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">random_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">rngs</span><span class="p">,</span> <span class="n">input_x</span><span class="p">,</span> <span class="kc">True</span><span class="p">)[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span>

        <span class="c1"># If params provided find unitialized params and replace with provided params</span>
        <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">random_params</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="n">unfreeze</span><span class="p">(</span><span class="n">random_params</span><span class="p">))</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="n">unfreeze</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">missing_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span><span class="p">:</span>
                <span class="n">params</span><span class="p">[</span><span class="n">missing_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_params</span><span class="p">[</span><span class="n">missing_key</span><span class="p">]</span>  <span class="c1"># type: ignore</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">freeze</span><span class="p">(</span><span class="n">unflatten_dict</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">random_params</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dropout_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gumble_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Encode the input.</span>
<span class="sd">        Args:</span>
<span class="sd">            pixel_values (jnp.ndarray): the input to the encoder.</span>
<span class="sd">            params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>
<span class="sd">            dropout_rng (Union[Any,jnp.ndarray], optional): the dropout rng. Defaults to None.</span>
<span class="sd">            gumble_rng (Union[Any,jnp.ndarray], optional): the gumbel rng. Defaults to None.</span>
<span class="sd">            train (bool, optional): Training or inference mode. Defaults to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle any PRNG if needed</span>
        <span class="n">rngs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout_rng</span><span class="p">}</span> <span class="k">if</span> <span class="n">dropout_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="p">)</span>
        <span class="n">rngs</span><span class="p">[</span><span class="s2">&quot;gumbel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gumble_rng</span> <span class="k">if</span> <span class="n">gumble_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span>
            <span class="n">pixel_values</span><span class="p">,</span>
            <span class="ow">not</span> <span class="n">train</span><span class="p">,</span>
            <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">encode</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">z</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dropout_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gumble_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Decode the latent vector.</span>

<span class="sd">        Args:</span>
<span class="sd">            z (jnp.ndarray): the latent vector.</span>
<span class="sd">            params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>
<span class="sd">            dropout_rng (Union[Any,jnp.ndarray], optional): the dropout rng. Defaults to None.</span>
<span class="sd">            gumble_rng (Union[Any,jnp.ndarray], optional): the gumbel rng. Defaults to None.</span>
<span class="sd">            train (bool, optional): Training or inference mode. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            the decoded image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle any PRNG if needed</span>
        <span class="n">rngs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout_rng</span><span class="p">}</span> <span class="k">if</span> <span class="n">dropout_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="p">)</span>
        <span class="n">rngs</span><span class="p">[</span><span class="s2">&quot;gumbel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gumble_rng</span> <span class="k">if</span> <span class="n">gumble_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span>
            <span class="n">z</span><span class="p">,</span>
            <span class="ow">not</span> <span class="n">train</span><span class="p">,</span>
            <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">decode</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode_code</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">z_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Decode the indices.</span>

<span class="sd">        Args:</span>
<span class="sd">            indices (jnp.ndarray): the indices.</span>
<span class="sd">            z_shape (Tuple[int, ...]): the shape of the latent vector.</span>
<span class="sd">            params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            the decoded image from indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">z_shape</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">decode_code</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Update the temperature of the model.</span>
<span class="sd">        Args:</span>
<span class="sd">            temperature (float): the temperature to update to.</span>
<span class="sd">            params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>
<span class="sd">        Returns:</span>
<span class="sd">            the updated temperature.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span>
            <span class="n">temperature</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">update_temperature</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">new_temperature</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dropout_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gumble_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Encode and decode the input.</span>

<span class="sd">        Args:</span>
<span class="sd">            pixel_values (jnp.ndarray): the input to the encoder.</span>
<span class="sd">            params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>
<span class="sd">            dropout_rng (Optional[jnp.ndarray], optional): the dropout rng. Defaults to None.</span>
<span class="sd">            gumble_rng (Optional[jnp.ndarray], optional): the gumbel rng. Defaults to None.</span>
<span class="sd">                If gumble_rng is None then the defult rng is used and produce deterministic results.</span>
<span class="sd">            train (bool, optional): Training or inference mode. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">                the encoded latent vector,</span>
<span class="sd">                the decoded image,</span>
<span class="sd">                the log prob of the latent vector,</span>
<span class="sd">                the indices of the latent vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check dtype</span>
        <span class="n">pixel_values</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">pixel_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="k">if</span> <span class="n">pixel_values</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="k">else</span> <span class="n">pixel_values</span>
        <span class="p">)</span>
        <span class="c1"># Handle any PRNG if needed</span>
        <span class="n">rngs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout_rng</span><span class="p">}</span> <span class="k">if</span> <span class="n">dropout_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">rngs</span><span class="p">[</span><span class="s2">&quot;gumbel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gumble_rng</span> <span class="k">if</span> <span class="n">gumble_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span> <span class="n">pixel_values</span><span class="p">,</span> <span class="ow">not</span> <span class="n">train</span><span class="p">,</span> <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h2 id="modules.vqgan.VQGANPreTrainedModel.__call__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dropout_rng</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gumble_rng</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Encode and decode the input.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>pixel_values</code></td>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the input to the encoder.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>params</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="flax.core.frozen_dict.FrozenDict">FrozenDict</span>]</code>
          </td>
          <td><p>the params of the model. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout_rng</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span>]</code>
          </td>
          <td><p>the dropout rng. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>gumble_rng</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span>]</code>
          </td>
          <td><p>the gumbel rng. Defaults to None.
If gumble_rng is None then the defult rng is used and produce deterministic results.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>train</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>Training or inference mode. Defaults to False.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the encoded latent vector,</p></td>
        </tr>
        <tr>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the decoded image,</p></td>
        </tr>
        <tr>
          <td>
                <code>float</code>
          </td>
          <td><p>the log prob of the latent vector,</p></td>
        </tr>
        <tr>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the indices of the latent vector.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/vqgan.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dropout_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">gumble_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Encode and decode the input.</span>

<span class="sd">    Args:</span>
<span class="sd">        pixel_values (jnp.ndarray): the input to the encoder.</span>
<span class="sd">        params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>
<span class="sd">        dropout_rng (Optional[jnp.ndarray], optional): the dropout rng. Defaults to None.</span>
<span class="sd">        gumble_rng (Optional[jnp.ndarray], optional): the gumbel rng. Defaults to None.</span>
<span class="sd">            If gumble_rng is None then the defult rng is used and produce deterministic results.</span>
<span class="sd">        train (bool, optional): Training or inference mode. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">            the encoded latent vector,</span>
<span class="sd">            the decoded image,</span>
<span class="sd">            the log prob of the latent vector,</span>
<span class="sd">            the indices of the latent vector.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check dtype</span>
    <span class="n">pixel_values</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">pixel_values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="k">if</span> <span class="n">pixel_values</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="k">else</span> <span class="n">pixel_values</span>
    <span class="p">)</span>
    <span class="c1"># Handle any PRNG if needed</span>
    <span class="n">rngs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout_rng</span><span class="p">}</span> <span class="k">if</span> <span class="n">dropout_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">rngs</span><span class="p">[</span><span class="s2">&quot;gumbel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gumble_rng</span> <span class="k">if</span> <span class="n">gumble_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span> <span class="n">pixel_values</span><span class="p">,</span> <span class="ow">not</span> <span class="n">train</span><span class="p">,</span> <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.vqgan.VQGANPreTrainedModel.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">VQGANConfig</span><span class="p">(),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">_do_init</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Initialize the model.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>config</code></td>
          <td>
                <code><span title="transformers.PretrainedConfig">PretrainedConfig</span></code>
          </td>
          <td><p>the config of the model. Defaults to VQGANConfig.</p></td>
          <td>
                <code>VQGANConfig()</code>
          </td>
        </tr>
        <tr>
          <td><code>input_shape</code></td>
          <td>
                <code><span title="typing.Tuple">Tuple</span></code>
          </td>
          <td><p>the input shape of the model.
Defaults to (1, 256, 256, 3).</p></td>
          <td>
                <code>(1, 256, 256, 3)</code>
          </td>
        </tr>
        <tr>
          <td><code>seed</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>the seed of the model. Defaults to 0.</p></td>
          <td>
                <code>0</code>
          </td>
        </tr>
        <tr>
          <td><code>dtype</code></td>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.dtype">dtype</span></code>
          </td>
          <td><p>the dtype of the computation. Defaults to jnp.float32.</p></td>
          <td>
                <code>jnp.float32</code>
          </td>
        </tr>
        <tr>
          <td><code>_do_init</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>whether to initialize the model. Defaults to True.</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/vqgan.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">PretrainedConfig</span> <span class="o">=</span> <span class="n">VQGANConfig</span><span class="p">(),</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="n">_do_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialize the model.</span>

<span class="sd">    Args:</span>
<span class="sd">        config (PretrainedConfig, optional): the config of the model. Defaults to VQGANConfig.</span>
<span class="sd">        input_shape (Tuple, optional): the input shape of the model.</span>
<span class="sd">            Defaults to (1, 256, 256, 3).</span>
<span class="sd">        seed (int, optional): the seed of the model. Defaults to 0.</span>
<span class="sd">        dtype (jnp.dtype, optional): the dtype of the computation. Defaults to jnp.float32.</span>
<span class="sd">        _do_init (bool, optional): whether to initialize the model. Defaults to True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config_class</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2"> has to be an instance of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config_class</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;module_class should be defined in derived classes&quot;</span><span class="p">)</span>
    <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_class</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">config</span><span class="p">,</span>
        <span class="n">module</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">_do_init</span><span class="o">=</span><span class="n">_do_init</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.vqgan.VQGANPreTrainedModel.decode" class="doc doc-heading">
<code class="highlight language-python"><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dropout_rng</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gumble_rng</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Decode the latent vector.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>z</code></td>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the latent vector.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>params</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="flax.core.frozen_dict.FrozenDict">FrozenDict</span>]</code>
          </td>
          <td><p>the params of the model. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout_rng</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Any">Any</span>, <span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span>]</code>
          </td>
          <td><p>the dropout rng. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>gumble_rng</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Any">Any</span>, <span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span>]</code>
          </td>
          <td><p>the gumbel rng. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>train</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>Training or inference mode. Defaults to False.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the decoded image.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/vqgan.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">decode</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dropout_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">gumble_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Decode the latent vector.</span>

<span class="sd">    Args:</span>
<span class="sd">        z (jnp.ndarray): the latent vector.</span>
<span class="sd">        params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>
<span class="sd">        dropout_rng (Union[Any,jnp.ndarray], optional): the dropout rng. Defaults to None.</span>
<span class="sd">        gumble_rng (Union[Any,jnp.ndarray], optional): the gumbel rng. Defaults to None.</span>
<span class="sd">        train (bool, optional): Training or inference mode. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        the decoded image.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Handle any PRNG if needed</span>
    <span class="n">rngs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout_rng</span><span class="p">}</span> <span class="k">if</span> <span class="n">dropout_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="p">)</span>
    <span class="n">rngs</span><span class="p">[</span><span class="s2">&quot;gumbel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gumble_rng</span> <span class="k">if</span> <span class="n">gumble_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span>
        <span class="n">z</span><span class="p">,</span>
        <span class="ow">not</span> <span class="n">train</span><span class="p">,</span>
        <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">decode</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.vqgan.VQGANPreTrainedModel.decode_code" class="doc doc-heading">
<code class="highlight language-python"><span class="n">decode_code</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">z_shape</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Decode the indices.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>indices</code></td>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the indices.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>z_shape</code></td>
          <td>
                <code><span title="typing.Tuple">Tuple</span>[int, ...]</code>
          </td>
          <td><p>the shape of the latent vector.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>params</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="flax.core.frozen_dict.FrozenDict">FrozenDict</span>]</code>
          </td>
          <td><p>the params of the model. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the decoded image from indices.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/vqgan.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">decode_code</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">indices</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">z_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Decode the indices.</span>

<span class="sd">    Args:</span>
<span class="sd">        indices (jnp.ndarray): the indices.</span>
<span class="sd">        z_shape (Tuple[int, ...]): the shape of the latent vector.</span>
<span class="sd">        params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        the decoded image from indices.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span>
        <span class="n">indices</span><span class="p">,</span>
        <span class="n">z_shape</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">decode_code</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.vqgan.VQGANPreTrainedModel.encode" class="doc doc-heading">
<code class="highlight language-python"><span class="n">encode</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dropout_rng</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gumble_rng</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Encode the input.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>pixel_values</code></td>
          <td>
                <code><span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span></code>
          </td>
          <td><p>the input to the encoder.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>params</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="flax.core.frozen_dict.FrozenDict">FrozenDict</span>]</code>
          </td>
          <td><p>the params of the model. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>dropout_rng</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Any">Any</span>, <span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span>]</code>
          </td>
          <td><p>the dropout rng. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>gumble_rng</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Any">Any</span>, <span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span>]</code>
          </td>
          <td><p>the gumbel rng. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>train</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>Training or inference mode. Defaults to False.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/vqgan.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">dropout_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">gumble_rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Encode the input.</span>
<span class="sd">    Args:</span>
<span class="sd">        pixel_values (jnp.ndarray): the input to the encoder.</span>
<span class="sd">        params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>
<span class="sd">        dropout_rng (Union[Any,jnp.ndarray], optional): the dropout rng. Defaults to None.</span>
<span class="sd">        gumble_rng (Union[Any,jnp.ndarray], optional): the gumbel rng. Defaults to None.</span>
<span class="sd">        train (bool, optional): Training or inference mode. Defaults to False.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Handle any PRNG if needed</span>
    <span class="n">rngs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout_rng</span><span class="p">}</span> <span class="k">if</span> <span class="n">dropout_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="p">)</span>
    <span class="n">rngs</span><span class="p">[</span><span class="s2">&quot;gumbel&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gumble_rng</span> <span class="k">if</span> <span class="n">gumble_rng</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span>
        <span class="n">pixel_values</span><span class="p">,</span>
        <span class="ow">not</span> <span class="n">train</span><span class="p">,</span>
        <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">encode</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.vqgan.VQGANPreTrainedModel.init_weights" class="doc doc-heading">
<code class="highlight language-python"><span class="n">init_weights</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Initialize the weights of the model. Get the params</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>rng</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="typing.Any">Any</span>, <span title="jax.numpy">jnp</span>.<span title="jax.numpy.ndarray">ndarray</span>]</code>
          </td>
          <td><p>the random number generator.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>input_shape</code></td>
          <td>
                <code><span title="typing.Tuple">Tuple</span></code>
          </td>
          <td><p>the input shape of the model.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>params</code></td>
          <td>
                <code><span title="flax.core.frozen_dict.FrozenDict">FrozenDict</span></code>
          </td>
          <td><p>the params of the model. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="flax.core.frozen_dict.FrozenDict">FrozenDict</span>[str, <span title="typing.Any">Any</span>]</code>
          </td>
          <td><p>initialized params of the model.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/vqgan.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">rng</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Initialize the weights of the model. Get the params</span>

<span class="sd">    Args:</span>
<span class="sd">        rng (Union[Any,jnp.ndarray]): the random number generator.</span>
<span class="sd">        input_shape (Tuple): the input shape of the model.</span>
<span class="sd">        params (FrozenDict, optional): the params of the model. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        initialized params of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># initialize model</span>
    <span class="n">input_x</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">params_rng</span><span class="p">,</span> <span class="n">dropout_rng</span><span class="p">,</span> <span class="n">gumble_rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">rngs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params_rng</span><span class="p">,</span>
        <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout_rng</span><span class="p">,</span>
        <span class="s2">&quot;gumbel&quot;</span><span class="p">:</span> <span class="n">gumble_rng</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">random_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">rngs</span><span class="p">,</span> <span class="n">input_x</span><span class="p">,</span> <span class="kc">True</span><span class="p">)[</span><span class="s2">&quot;params&quot;</span><span class="p">]</span>

    <span class="c1"># If params provided find unitialized params and replace with provided params</span>
    <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">random_params</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="n">unfreeze</span><span class="p">(</span><span class="n">random_params</span><span class="p">))</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="n">unfreeze</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">missing_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span><span class="p">:</span>
            <span class="n">params</span><span class="p">[</span><span class="n">missing_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_params</span><span class="p">[</span><span class="n">missing_key</span><span class="p">]</span>  <span class="c1"># type: ignore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">freeze</span><span class="p">(</span><span class="n">unflatten_dict</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">random_params</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.vqgan.VQGANPreTrainedModel.update_temperature" class="doc doc-heading">
<code class="highlight language-python"><span class="n">update_temperature</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Update the temperature of the model.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>temperature</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>the temperature to update to.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>params</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="flax.core.frozen_dict.FrozenDict">FrozenDict</span>]</code>
          </td>
          <td><p>the params of the model. Defaults to None.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>float</code>
          </td>
          <td><p>the updated temperature.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/vqgan.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">update_temperature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Update the temperature of the model.</span>
<span class="sd">    Args:</span>
<span class="sd">        temperature (float): the temperature to update to.</span>
<span class="sd">        params (Optional[FrozenDict], optional): the params of the model. Defaults to None.</span>
<span class="sd">    Returns:</span>
<span class="sd">        the updated temperature.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_temperature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">},</span>
        <span class="n">temperature</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">update_temperature</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">new_temperature</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div><h3 id="vqgandiscriminator">VQGanDiscriminator</h3>
<p><code>VQGanDiscriminator</code> in <a href="https://github.com/WolodjaZ/jax-vqgan/blob/e67c52cbb02fc39fbbfacc1ad06f40e6a7d53a79/modules/vqgan.py#L613"><code>modules.vqgan</code></a>, response for Discriminator architecture. This class is based on <code>FlaxPreTrainedModel</code> which gives ous abilities to push the architecture to Hugging Face Hub.</p>


<div class="doc doc-object doc-class">


<a id="modules.vqgan.VQGanDiscriminator"></a>
  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><span title="transformers.modeling_flax_utils.FlaxPreTrainedModel">FlaxPreTrainedModel</span></code></p>

  
      <p>VQGAN discriminator model.</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>module_class</code></td>
          <td>
                <code><span title="flax.linen">nn</span>.<span title="flax.linen.Module">Module</span></code>
          </td>
          <td><p>the discriminator module class (NLayerDiscriminator).</p></td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>modules/vqgan.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">VQGanDiscriminator</span><span class="p">(</span><span class="n">FlaxPreTrainedModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;VQGAN discriminator model.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        module_class (nn.Module): the discriminator module class (NLayerDiscriminator).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">module_class</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">NLayerDiscriminator</span>  <span class="c1"># type: ignore</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">DiscConfig</span> <span class="o">=</span> <span class="n">DiscConfig</span><span class="p">(),</span>
        <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">_do_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_class</span><span class="p">(</span>
            <span class="n">ndf</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">ndf</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">output_last_dim</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">config</span><span class="p">,</span>
            <span class="n">module</span><span class="p">,</span>
            <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">_do_init</span><span class="o">=</span><span class="n">_do_init</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">params_rng</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FrozenDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="c1"># initialize model</span>
        <span class="n">input_x</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">random_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">params_rng</span><span class="p">,</span> <span class="n">input_x</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="c1"># If params provided find unitialized params and replace with provided params</span>
        <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">random_params</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="n">unfreeze</span><span class="p">(</span><span class="n">random_params</span><span class="p">))</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="n">unfreeze</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">missing_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span><span class="p">:</span>
                <span class="n">params</span><span class="p">[</span><span class="n">missing_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_params</span><span class="p">[</span><span class="n">missing_key</span><span class="p">]</span>  <span class="c1"># type: ignore</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_missing_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">freeze</span><span class="p">(</span><span class="n">unflatten_dict</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">random_params</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_stats</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FrozenDict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="c1"># Handle any PRNG if needed</span>
        <span class="k">if</span> <span class="n">batch_stats</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dict_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">,</span> <span class="s2">&quot;batch_stats&quot;</span><span class="p">:</span> <span class="n">batch_stats</span><span class="p">}</span>
        <span class="k">elif</span> <span class="n">batch_stats</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dict_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">],</span> <span class="s2">&quot;batch_stats&quot;</span><span class="p">:</span> <span class="n">batch_stats</span><span class="p">}</span>
        <span class="k">elif</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dict_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">params</span><span class="p">,</span> <span class="s2">&quot;batch_stats&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">]}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dict_params</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">],</span>
                <span class="s2">&quot;batch_stats&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">],</span>
            <span class="p">}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="n">dict_params</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">mutable</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;batch_stats&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="kc">False</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div><h3 id="tensorflowdataset">TensorflowDataset</h3>
<p><code>TensorflowDataset</code> in <a href="https://github.com/WolodjaZ/jax-vqgan/blob/e67c52cbb02fc39fbbfacc1ad06f40e6a7d53a79/modules/utils.py#L162"><code>modules.utils</code></a>, response for loading Tensorflow datasets and prepering them. This class is based on <a href="https://github.com/WolodjaZ/jax-vqgan/blob/e67c52cbb02fc39fbbfacc1ad06f40e6a7d53a79/modules/utils.py#L72"><code>BaseDataset</code></a></p>


<div class="doc doc-object doc-class">


<a id="modules.utils.TensorflowDataset"></a>
  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="modules.utils.BaseDataset" href="../reference/#modules.utils.BaseDataset">BaseDataset</a></code></p>

  
      <p>Tensorflow dataset.</p>


        <details class="quote">
          <summary>Source code in <code>modules/utils.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TensorflowDataset</span><span class="p">(</span><span class="n">BaseDataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tensorflow dataset.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Load the dataset.</span>
<span class="sd">        Args:</span>
<span class="sd">            train: If the dataset is for training.</span>
<span class="sd">        Returns:</span>
<span class="sd">            The dataset.&quot;&quot;&quot;</span>

        <span class="c1"># if you get error &#39;Too many open files&#39; one can resolve it doing what this issue proposed</span>
        <span class="c1"># https://github.com/tensorflow/datasets/issues/1441#issuecomment-581660890</span>
        <span class="c1"># Below is the code to resolve it</span>
        <span class="c1"># import resource</span>
        <span class="c1"># low, high = resource.getrlimit(resource.RLIMIT_NOFILE)</span>
        <span class="c1"># resource.setrlimit(resource.RLIMIT_NOFILE, (high, high))</span>
        <span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="s2">&quot;validation&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span>
            <span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">autograph</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">do_not_convert</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s2">&quot;validation&quot;</span><span class="p">:</span>
                <span class="n">ds</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span>
                <span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">autograph</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">do_not_convert</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>

        <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h2 id="modules.utils.TensorflowDataset.load_dataset" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load_dataset</span><span class="p">(</span><span class="n">train</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Load the dataset.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>train</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>If the dataset is for training.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="tensorflow">tf</span>.<span title="tensorflow.data">data</span>.<span title="tf.data.Dataset">Dataset</span></code>
          </td>
          <td><p>The dataset.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/utils.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Load the dataset.</span>
<span class="sd">    Args:</span>
<span class="sd">        train: If the dataset is for training.</span>
<span class="sd">    Returns:</span>
<span class="sd">        The dataset.&quot;&quot;&quot;</span>

    <span class="c1"># if you get error &#39;Too many open files&#39; one can resolve it doing what this issue proposed</span>
    <span class="c1"># https://github.com/tensorflow/datasets/issues/1441#issuecomment-581660890</span>
    <span class="c1"># Below is the code to resolve it</span>
    <span class="c1"># import resource</span>
    <span class="c1"># low, high = resource.getrlimit(resource.RLIMIT_NOFILE)</span>
    <span class="c1"># resource.setrlimit(resource.RLIMIT_NOFILE, (high, high))</span>
    <span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="s2">&quot;validation&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span>
        <span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">autograph</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">do_not_convert</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s2">&quot;validation&quot;</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span>
            <span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">autograph</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">do_not_convert</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">e</span>

    <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">


<a id="modules.utils.BaseDataset"></a>
  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><span title="abc.ABC">ABC</span></code></p>

  
      <p>Load the dataset. Abstract method.</p>


        <details class="quote">
          <summary>Source code in <code>modules/utils.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BaseDataset</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Load the dataset. Abstract method.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">DataConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Set the dataset.</span>
<span class="sd">        Args:</span>
<span class="sd">            train: If the dataset is for training.</span>
<span class="sd">            config: The config for the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset_root</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_transforms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_transforms</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Transforms must be provided for training.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_name</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">train_params</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">test_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Dataset is empty.&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Load the dataset.</span>
<span class="sd">        Args:</span>
<span class="sd">            train: If the dataset is for training.</span>
<span class="sd">        Returns:</span>
<span class="sd">            The dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the length of the dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Preprocess the image.</span>
<span class="sd">        Args:</span>
<span class="sd">            image: The image to preprocess.</span>
<span class="sd">        Returns:</span>
<span class="sd">            The preprocessed image.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">aug_fn</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="n">image</span><span class="p">}</span>
            <span class="n">aug_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">)</span>
            <span class="n">aug_img</span> <span class="o">=</span> <span class="n">aug_data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
            <span class="n">aug_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">aug_img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
            <span class="n">aug_img</span> <span class="o">=</span> <span class="p">(</span><span class="n">aug_img</span> <span class="o">-</span> <span class="n">IMAGENET_STANDARD_MEAN</span><span class="p">)</span> <span class="o">/</span> <span class="n">IMAGENET_STANDARD_STD</span>
            <span class="n">aug_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">aug_img</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">aug_img</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_transforms</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">numpy_function</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">aug_fn</span><span class="p">,</span> <span class="n">inp</span><span class="o">=</span><span class="p">[</span><span class="n">image</span><span class="p">],</span> <span class="n">Tout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
            <span class="n">image</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span> <span class="o">-</span> <span class="n">IMAGENET_STANDARD_MEAN</span><span class="p">)</span> <span class="o">/</span> <span class="n">IMAGENET_STANDARD_STD</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">image</span>

    <span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the dataset.</span>
<span class="sd">        Returns:</span>
<span class="sd">            The dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">16</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">shuffle</span> <span class="k">else</span> <span class="n">dataset</span>
        <span class="k">return</span> <span class="n">dataset</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h2 id="modules.utils.BaseDataset.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Set the dataset.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>train</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>If the dataset is for training.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>config</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.config.DataConfig" href="../reference/#modules.config.DataConfig">DataConfig</a></code>
          </td>
          <td><p>The config for the dataset.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/utils.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">DataConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Set the dataset.</span>
<span class="sd">    Args:</span>
<span class="sd">        train: If the dataset is for training.</span>
<span class="sd">        config: The config for the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset_root</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_transforms</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_transforms</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Transforms must be provided for training.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_name</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">dataset_name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">train_params</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="n">config</span><span class="o">.</span><span class="n">test_params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Dataset is empty.&quot;</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.utils.BaseDataset.__len__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__len__</span><span class="p">()</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Return the length of the dataset.</p>

      <details class="quote">
        <summary>Source code in <code>modules/utils.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Return the length of the dataset.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.utils.BaseDataset.get_dataset" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_dataset</span><span class="p">()</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Return the dataset.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="tensorflow">tf</span>.<span title="tensorflow.data">data</span>.<span title="tf.data.Dataset">Dataset</span></code>
          </td>
          <td><p>The dataset.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/utils.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Return the dataset.</span>
<span class="sd">    Returns:</span>
<span class="sd">        The dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">16</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">shuffle</span> <span class="k">else</span> <span class="n">dataset</span>
    <span class="k">return</span> <span class="n">dataset</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.utils.BaseDataset.load_dataset" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load_dataset</span><span class="p">(</span><span class="n">train</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h2>


  <div class="doc doc-contents ">
  
      <p>Load the dataset.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>train</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>If the dataset is for training.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="tensorflow">tf</span>.<span title="tensorflow.data">data</span>.<span title="tf.data.Dataset">Dataset</span></code>
          </td>
          <td><p>The dataset.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/utils.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Load the dataset.</span>
<span class="sd">    Args:</span>
<span class="sd">        train: If the dataset is for training.</span>
<span class="sd">    Returns:</span>
<span class="sd">        The dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div><h3 id="dataloader">DataLoader</h3>
<p><code>DataLoader</code> in <a href="https://github.com/WolodjaZ/jax-vqgan/blob/e67c52cbb02fc39fbbfacc1ad06f40e6a7d53a79/modules/utils.py#L185"><code>modules.utils</code></a>, responses for wraping datasets and creating batches. Similar to <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">Pytorch Dataloader</a></p>


<div class="doc doc-object doc-class">


<a id="modules.utils.DataLoader"></a>
  <div class="doc doc-contents first">

  
      <p>Dataloader similar as in pytorch.</p>


        <details class="quote">
          <summary>Source code in <code>modules/utils.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DataLoader</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Dataloader similar as in pytorch.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">BaseDataset</span><span class="p">,</span> <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create a data loader.</span>
<span class="sd">        Args:</span>
<span class="sd">            dataset (BaseDataset): The dataset to load.</span>
<span class="sd">            distributed (bool): If the data is distributed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">=</span> <span class="n">distributed</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the length of the dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the dataset in dataloader style.&quot;&quot;&quot;</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">()</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="p">:</span>
            <span class="n">per_core_bs</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()))</span>
            <span class="k">assert</span> <span class="n">remainder</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">per_core_bs</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()),</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># ds = map(lambda x: x._numpy(), ds.prefetch(tf.data.AUTOTUNE))</span>
        <span class="c1"># data = flax.jax_utils.prefetch_to_device(ds, 3) if self.dist else ds</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">))</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">flax</span><span class="o">.</span><span class="n">jax_utils</span><span class="o">.</span><span class="n">prefetch_to_device</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="k">else</span> <span class="n">ds</span>
        <span class="k">return</span> <span class="n">ds</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h2 id="modules.utils.DataLoader.__call__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Return the dataset in dataloader style.</p>

      <details class="quote">
        <summary>Source code in <code>modules/utils.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Return the dataset in dataloader style.&quot;&quot;&quot;</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">()</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="p">:</span>
        <span class="n">per_core_bs</span><span class="p">,</span> <span class="n">remainder</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()))</span>
        <span class="k">assert</span> <span class="n">remainder</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">per_core_bs</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()),</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># ds = map(lambda x: x._numpy(), ds.prefetch(tf.data.AUTOTUNE))</span>
    <span class="c1"># data = flax.jax_utils.prefetch_to_device(ds, 3) if self.dist else ds</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">))</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">flax</span><span class="o">.</span><span class="n">jax_utils</span><span class="o">.</span><span class="n">prefetch_to_device</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="k">else</span> <span class="n">ds</span>
    <span class="k">return</span> <span class="n">ds</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.utils.DataLoader.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">distributed</span><span class="p">)</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Create a data loader.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>dataset</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="modules.utils.BaseDataset" href="../reference/#modules.utils.BaseDataset">BaseDataset</a></code>
          </td>
          <td><p>The dataset to load.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>distributed</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>If the data is distributed.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>modules/utils.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">BaseDataset</span><span class="p">,</span> <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Create a data loader.</span>
<span class="sd">    Args:</span>
<span class="sd">        dataset (BaseDataset): The dataset to load.</span>
<span class="sd">        distributed (bool): If the data is distributed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span> <span class="o">=</span> <span class="n">dataset</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">=</span> <span class="n">distributed</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="modules.utils.DataLoader.__len__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__len__</span><span class="p">()</span></code>

</h2>


  <div class="doc doc-contents ">
  
      <p>Return the length of the dataset.</p>

      <details class="quote">
        <summary>Source code in <code>modules/utils.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Return the length of the dataset.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_placeholder</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../tutorials/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Tutorials üôá" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Tutorials üôá
            </div>
          </div>
        </a>
      
      
        
        <a href="../reference/" class="md-footer__link md-footer__link--next" aria-label="Next: API Reference" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              API Reference
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6c3db9e.min.js"></script>
      
    
  </body>
</html>