
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.10">
    
    
      
        <title>Tutorials üôá - VQGAN JAX/Flax Docs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.472b142f.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.08040f6c.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="None" data-md-color-accent="None">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#0-prepare-environment" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="VQGAN JAX/Flax Docs" class="md-header__button md-logo" aria-label="VQGAN JAX/Flax Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            VQGAN JAX/Flax Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tutorials üôá
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/WolodjaZ/jax-vqgan" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="VQGAN JAX/Flax Docs" class="md-nav__button md-logo" aria-label="VQGAN JAX/Flax Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    VQGAN JAX/Flax Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/WolodjaZ/jax-vqgan" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Welcome to Docs üëã
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Tutorials üôá
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Tutorials üôá
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#0-prepare-environment" class="md-nav__link">
    0. Prepare environment
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-imports" class="md-nav__link">
    1. Imports
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-load-configs" class="md-nav__link">
    2. Load configs
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-prepare-datasets-and-dataloaders" class="md-nav__link">
    3. Prepare datasets and dataloaders
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-prepare-train-module" class="md-nav__link">
    4. Prepare train module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-lets-start-trining" class="md-nav__link">
    5 Let`s start trining ‚úä
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-what-now-we-can-do" class="md-nav__link">
    6. What now we can do
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-lets-look-at-the-model" class="md-nav__link">
    7. Lets look at the model
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../how-to-guides/" class="md-nav__link">
        How-To Guides üìö
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../reference/" class="md-nav__link">
        API Reference
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../explanation/" class="md-nav__link">
        Explanation ü§Ø
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../changelog/" class="md-nav__link">
        Changelog ‚è≥
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#0-prepare-environment" class="md-nav__link">
    0. Prepare environment
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-imports" class="md-nav__link">
    1. Imports
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-load-configs" class="md-nav__link">
    2. Load configs
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-prepare-datasets-and-dataloaders" class="md-nav__link">
    3. Prepare datasets and dataloaders
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-prepare-train-module" class="md-nav__link">
    4. Prepare train module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-lets-start-trining" class="md-nav__link">
    5 Let`s start trining ‚úä
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-what-now-we-can-do" class="md-nav__link">
    6. What now we can do
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-lets-look-at-the-model" class="md-nav__link">
    7. Lets look at the model
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/WolodjaZ/jax-vqgan/edit/master/docs/tutorials.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


  <h1>Tutorials üôá</h1>

<p>This tutorial demonstrate how to train VQGAN in JAX/Flax using our pipeline. For the tutorial we will train on <a href="https://www.tensorflow.org/datasets/catalog/imagenette">imagenette</a> datasets.</p>
<p>Note: This notebook will be re-evaluated when I get access to GPU to fully train this model, for now I am poor jobless person üòû.</p>
<h2 id="0-prepare-environment">0. Prepare environment</h2>
<p>We use <a href="https://pdm.fming.dev/latest/">pdm</a> a modern Python package and dependency manager so thanks to it one can easily reproduce our code.
First you need to create virtual environment and install packages. You can do it with</p>
<pre><code class="language-bash">python -m venv venv
pip  install -r requirements.txt
</code></pre>
<p>Or via pdm. Firstly install pdm using this <a href="https://pdm.fming.dev/latest/">url</a>. Then you:</p>
<pre><code class="language-bash">pdm install
pdm install --dev
pdm run pre-commit install
</code></pre>
<p>Now you are all set for the working with this project hurray üéâüéâüéâ!
<strong>Just remember all useful scripts are in</strong>:</p>
<pre><code class="language-bash">pdm run --list
pdm run #run command
</code></pre>
<p><strong>And if you wanna run some commands you need to <code>pdm run &lt;command&gt;</code></strong></p>
<pre><code class="language-python"># Install dependencies
%pip install -r ../requirements.txt

# you can also create virtual environment and install dependencies with
%invoke venv # recommended
</code></pre>
<h2 id="1-imports">1. Imports</h2>
<p>Import OmegaConf, LoadConfig, TrainerVQGan, DataLoader, TensorflowDataset. <a href="https://omegaconf.readthedocs.io/en/2.2_branch/#">OmegaConf</a> is a library which will handle loading yaml file with our configs. Our pipeline is managed basically with yaml files specifying architecture, trainer, dataset loading and processing. LoadConfig is our dataclass config which will take omegaconf dict and prepare configs for training and data loading. TensorflowDataset and DataLoader are our objects for preparing datasets and creating something similar to PyTorch data loaders. Lastly TrainerVQGan is object which will take care of creating models, training them and logging.</p>
<pre><code class="language-python"># External libraries
# flake8: noqa: E402
import sys

from omegaconf import OmegaConf

# Internal libraries
sys.path.insert(0, &quot;../&quot;)
from modules.config import LoadConfig
from modules.training import TrainerVQGan
from modules.utils import DataLoader, TensorflowDataset
</code></pre>
<pre><code>/Users/vladimirzaigrajew/Documents/projects/jax-vqgan/myenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
WARNING:absl:GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.
</code></pre>
<h2 id="2-load-configs">2. Load configs</h2>
<p>Now lets load our training configs. For now we created three sample configs located in <code>conf</code> folder:
- <code>config.yaml</code> my training config
- <code>imagenet.yaml</code> official training config for training on imagenet dataset
- <code>gumbel.yaml</code> official training config with Gumbel-max trick on imagenet dataset</p>
<p>You can create your own config if you want to but for this tutorial we will use <code>config.yaml</code>.</p>
<pre><code class="language-python">config_path = &quot;../conf/config.yaml&quot;
cfg_omega = OmegaConf.load(config_path)
print(OmegaConf.to_yaml(cfg_omega))
</code></pre>
<pre><code>train:
  model_name: vqgan_imagenette
  model_hparams:
    embed_dim: 256
    n_embed: 1024
    double_z: false
    z_channels: 256
    in_channels: 3
    out_ch: 3
    ch: 128
    ch_mult:
    - 1
    - 1
    - 2
    - 2
    - 4
    act_name: gelu
    num_res_blocks: 2
    attn_resolutions:
    - 16
    dropout: 0.0
  disc_hparams:
    input_last_dim: 3
  save_dir: ../../datasets/vqgan_model_save
  log_dir: ../../datasets/vqgan_log_dir
  check_val_every_n_epoch: 1
  log_img_every_n_epoch: 5
  input_shape:
  - 256
  - 256
  - 3
  codebook_weight: 1.0
  monitor: total_loss
  recon_loss: l1
  disc_loss: hinge
  disc_weight: 0.8
  num_epochs: 10
  dtype: float32
  distributed: false
  seed: 42
  optimizer:
    _target_: optax.adamw
    learning_rate: 4.5e-06
    b1: 0.9
    b2: 0.999
    weight_decay: 0.0001
  optimizer_disc:
    _target_: optax.adamw
    learning_rate: 4.5e-06
    b1: 0.9
    b2: 0.999
    weight_decay: 0.0001
  disc_start: 7
  temp_scheduler: null
data:
  train_params:
    batch_size: 4
    shuffle: true
  test_params:
    batch_size: 8
    shuffle: false
  dataset_name: imagenette
  dataset_root: ../../datasets
  transform:
    __version__: 1.3.0
    transform:
      __class_fullname__: Compose
      additional_targets: {}
      bbox_params: null
      keypoint_params: null
      p: 1.0
      transforms:
      - __class_fullname__: RandomBrightnessContrast
        always_apply: false
        brightness_by_max: true
        brightness_limit:
        - -0.1
        - 0.1
        contrast_limit:
        - -0.2
        - 0.2
        p: 0.5
      - __class_fullname__: HorizontalFlip
        always_apply: false
        p: 0.5
  size: 256
</code></pre>
<p>We see that we have two sections <code>train</code> which corresponds to setting trainer and architectures and <code>data</code> specifying datasets, augmentation and preprocessing.</p>
<pre><code class="language-python">cfg_omega_dict = OmegaConf.to_container(cfg_omega)
cfg_omega_dict[&quot;train&quot;][&quot;num_epochs&quot;] = 1  # reduce number of epochs for testing
cfg = LoadConfig(**cfg_omega)
print(cfg)
</code></pre>
<pre><code>LoadConfig(train=TrainConfig(model_name='vqgan_imagenette', model_hparams=VQGANConfig {
  "act_name": "gelu",
  "attn_resolutions": [
    16
  ],
  "beta": 0.25,
  "ch": 128,
  "ch_mult": [
    1,
    1,
    2,
    2,
    4
  ],
  "double_z": false,
  "dropout": 0.0,
  "embed_dim": 256,
  "give_pre_end": false,
  "gumb_temp": 1.0,
  "in_channels": 3,
  "kl_weight": 0.0005,
  "n_embed": 1024,
  "num_res_blocks": 2,
  "num_resolutions": 5,
  "out_ch": 3,
  "resamp_with_conv": true,
  "resolution": 256,
  "transformers_version": "4.24.0",
  "use_gumbel": false,
  "z_channels": 256
}
, disc_hparams=DiscConfig {
  "input_last_dim": 3,
  "n_layers": 3,
  "ndf": 64,
  "output_last_dim": 1,
  "resolution": 256,
  "transformers_version": "4.24.0"
}
, save_dir='../../datasets/vqgan_model_save', log_dir='../../datasets/vqgan_log_dir', check_val_every_n_epoch=1, log_img_every_n_epoch=5, input_shape=(256, 256, 3), codebook_weight=1.0, monitor='total_loss', recon_loss='l1', disc_loss='hinge', disc_weight=0.8, num_epochs=10, dtype=&lt;class 'jax.numpy.float32'&gt;, distributed=False, seed=42, optimizer=GradientTransformation(init=&lt;function chain.&lt;locals&gt;.init_fn at 0x7fb5569c9e50&gt;, update=&lt;function chain.&lt;locals&gt;.update_fn at 0x7fb5569c9f70&gt;), optimizer_disc=GradientTransformation(init=&lt;function chain.&lt;locals&gt;.init_fn at 0x7fb5569e6310&gt;, update=&lt;function chain.&lt;locals&gt;.update_fn at 0x7fb5569e63a0&gt;), disc_start=7, temp_scheduler=None), data=DataConfig(train_params=DataParams(batch_size=4, shuffle=True), test_params=DataParams(batch_size=8, shuffle=False), dataset_name='imagenette', dataset_root='../../datasets', transform={'__version__': '1.3.0', 'transform': {'__class_fullname__': 'Compose', 'additional_targets': {}, 'bbox_params': None, 'keypoint_params': None, 'p': 1.0, 'transforms': [{'__class_fullname__': 'RandomBrightnessContrast', 'always_apply': False, 'brightness_by_max': True, 'brightness_limit': [-0.1, 0.1], 'contrast_limit': [-0.2, 0.2], 'p': 0.5}, {'__class_fullname__': 'HorizontalFlip', 'always_apply': False, 'p': 0.5}]}}, size=256))
</code></pre>
<p>Now if you look more closely and compare two outputs you will see some inequalities, because <code>LoadConfig</code> does some preprocessing and instantiating some objects.</p>
<h2 id="3-prepare-datasets-and-dataloaders">3. Prepare datasets and dataloaders</h2>
<p>Having our train and data configs now lets create datasets and dataloaders.</p>
<pre><code class="language-python">print(cfg.data)
</code></pre>
<pre><code>DataConfig(train_params=DataParams(batch_size=4, shuffle=True), test_params=DataParams(batch_size=8, shuffle=False), dataset_name='imagenette', dataset_root='../../datasets', transform={'__version__': '1.3.0', 'transform': {'__class_fullname__': 'Compose', 'additional_targets': {}, 'bbox_params': None, 'keypoint_params': None, 'p': 1.0, 'transforms': [{'__class_fullname__': 'RandomBrightnessContrast', 'always_apply': False, 'brightness_by_max': True, 'brightness_limit': [-0.1, 0.1], 'contrast_limit': [-0.2, 0.2], 'p': 0.5}, {'__class_fullname__': 'HorizontalFlip', 'always_apply': False, 'p': 0.5}]}}, size=256)
</code></pre>
<p>Config for data have information about train and test datasets, size of the images and augmentations which will be used with <a href="">albumentations</a> frameworks</p>
<pre><code class="language-python">print(f&quot;In train config we have information about data datatype. We use {cfg.train.dtype}&quot;)

dataset_train_class = TensorflowDataset(train=True, dtype=cfg.train.dtype, config=cfg.data)
dataset_test_class = TensorflowDataset(train=False, dtype=cfg.train.dtype, config=cfg.data)
</code></pre>
<pre><code>In train config we have information about data datatype. We use &lt;class 'jax.numpy.float32'&gt;
</code></pre>
<p>Let`s look on data.</p>
<pre><code class="language-python"># Framework for visualization
from matplotlib import pyplot as plt

%matplotlib inline

from modules.utils import post_processing
</code></pre>
<pre><code class="language-python">dataset = dataset_test_class.get_dataset()
dataset_iter = iter(dataset)
data = next(dataset_iter)
print(f&quot;Our data have shape: {data.shape} and data type: {data.dtype}&quot;)
</code></pre>
<pre><code>Our data have shape: (256, 256, 3) and data type: &lt;dtype: 'float32'&gt;


2022-11-23 14:40:16.429179: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
</code></pre>
<p>We need to post process data because our data for modal is standardized and normalized.</p>
<pre><code class="language-python">data_postprocessed = post_processing(data.numpy())
plt.imshow(data_postprocessed)
plt.show()
</code></pre>
<p><img alt="png" src="../tutorials_files/tutorials_18_0.png" /></p>
<p>Now let's look at dataloader data</p>
<pre><code class="language-python">print(
    f&quot;We use again information from train config about distributed training:{cfg.train.distributed}&quot;
)
loader_train = DataLoader(dataset=dataset_train_class, distributed=cfg.train.distributed)
loader_val = DataLoader(dataset=dataset_test_class, distributed=cfg.train.distributed)
</code></pre>
<pre><code>We use again information from train config about distributed training: False
</code></pre>
<pre><code class="language-python">dataloader_iter = iter(loader_val())
data = next(dataloader_iter)
print(f&quot;Our data have shape: {data.shape} and data type: {data.dtype}&quot;)
</code></pre>
<pre><code>Our data have shape: (8, 256, 256, 3) and data type: float32


2022-11-23 14:40:20.057526: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
</code></pre>
<pre><code class="language-python">data = data[:8]
data_postprocessed = [post_processing(img) for img in data]
fig, axs = plt.subplots(2, 4, figsize=(12, 8))
for i, ax in enumerate(axs.flat):
    ax.imshow(data_postprocessed[i])
    ax.axis(&quot;off&quot;)
plt.show()
</code></pre>
<p><img alt="png" src="../tutorials_files/tutorials_22_0.png" /></p>
<h2 id="4-prepare-train-module">4. Prepare train module</h2>
<p>You don't need to create architecture, inicialize it etc. Because for doing it we have our <strong>trainer</strong> <code>TrainerVQGan</code>. There we have prepared training, logging to Tensorboard and checkpointing it. Additionaly pmaping and jiting we also took care of it for you. THANK YOU üò§.</p>
<pre><code class="language-python">model = TrainerVQGan(module_config=cfg.train)
</code></pre>
<h2 id="5-lets-start-trining">5 Let`s start trining ‚úä</h2>
<pre><code class="language-python">model.train_model(loader_train, loader_val)
</code></pre>
<h2 id="6-what-now-we-can-do">6. What now we can do</h2>
<p>You can now save model, but we always save model when we gat better results. You can also load model.</p>
<pre><code class="language-python">if model.checkpoint_exists():
    model.load_model()
</code></pre>
<p>One can also see tensorboard results</p>
<pre><code class="language-python">%reload_ext tensorboard
%tensorboard --logdir cfg.train.log_dir --host localhost --port 8888
</code></pre>
<h2 id="7-lets-look-at-the-model">7. Lets look at the model</h2>
<p>Now lets take the model and look at the samples</p>
<pre><code class="language-python"># external libraries
import jax
import numpy as np

# internal libraries
from modules.utils import make_img_grid
</code></pre>
<pre><code class="language-python"># Prepare data
dataloader_iter = iter(loader_val())
data = next(dataloader_iter)
data = data[:8]
</code></pre>
<pre><code>2022-11-23 14:54:33.304669: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
</code></pre>
<pre><code class="language-python"># Generate images
reconst_imgs = model.model(data)[0]
reconst_imgs = jax.device_get(reconst_imgs)
</code></pre>
<pre><code class="language-python"># Plot and add to tensorboard
imgs = np.stack([data, reconst_imgs], axis=1).reshape(-1, *data.shape[1:])
imgs = np.stack([post_processing(img, resize=128) for img in imgs], axis=0)
img_to_log = make_img_grid(imgs, nrows=2)
plt.figure(figsize=(16, 12))
plt.imshow(img_to_log)
plt.show()
</code></pre>
<p><img alt="png" src="../tutorials_files/tutorials_35_0.png" /></p>
<p>Congrats üëèüëèüëè! You made it to the end of the training example. You can revisit the same example, but structured differently as a couple of Python modules, test modules, config files, another Colab, and documentation in Git repo:</p>
<p><a href="https://github.com/WolodjaZ/jax-vqgan/blob/main/notebooks/example.ipynb">https://github.com/WolodjaZ/jax-vqgan/blob/main/notebooks/example.ipynb</a></p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href=".." class="md-footer__link md-footer__link--prev" aria-label="Previous: Welcome to Docs üëã" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Welcome to Docs üëã
            </div>
          </div>
        </a>
      
      
        
        <a href="../how-to-guides/" class="md-footer__link md-footer__link--next" aria-label="Next: How-To Guides üìö" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              How-To Guides üìö
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.16e2a7d4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6c3db9e.min.js"></script>
      
    
  </body>
</html>